---
layout: edition
title: MediaEval 2026
year: 2026
permalink: /editions/2026/
---

The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data, with a focus on analysis, exploration, and information access and retrieval. Signup is open to anyone who wishes to participate. There are two types of participation: “standard” participation requires creating an algorithm for addressing the challenge and “insight” participation requires gaining new insight, e.g., into the data, the evaluation procedure, or the implications of the task. Participating teams submit their algorithms (for the “standard” participation) and write up papers for the working notes proceedings (both “standard” and “insight” participation). The larger aim of MediaEval is to promote reproducible research that makes multimedia a positive force for society.

In the 2026 edition, we will offer the same slate of tasks as in the 2025 edition in order to provide opportunities for teams who were not able to participate in 2025. Also, we will put special emphasis on “insight” participation. Specifically, we welcome “Quest for Insight” papers that examine characteristics of the data and the task definitions, the strengths and weaknesses of particular types of approaches, observations about the evaluation procedure, and implications of the task. 

Participating teams present their work at the annual MediaEval workshop. The workshop will take place in Amsterdam, Netherlands, and also offer the possibility of online participation. If you are an early career researcher and funding restrictions are preventing your participation, please inquire about possible travel support. This edition will be co-located with ACM International Conference on Multimedia Retrieval - [ICMR2026](https://icmr2026.org/).


##### Registration:
Signup for MediaEval 2026 opens in January.

##### MediaEval 2026 Schedule:
* Registration for task participation opens: January 2026
* Test data release: 1 March 2026
* Runs due: 1 May 2026
* Working notes papers due: 31 May 2026
* MediaEval 2026 Workshop, Sat.-Sun. 15-16 June 2026, Amsterdam, Netherlands and Online, co-located with ACM ICMR 2026

##### The MediaEval Coordination Committee (2026): 
* Mihai Gabriel Constantin, National University of Science and Technology Politehnica Bucharest, Romania
* Steven Hicks, SimulaMet, Norway
* Martha Larson, Radboud University, Netherlands

### Task List

##### Medico 2026: Visual Question Answering (VQA) for Gastrointestinal Imaging

Medico 2026 focuses on Visual Question Answering (VQA) for gastrointestinal (GI) imaging, with an emphasis on explainability, clinical safety, and multimodal reasoning. The task leverages the expanded Kvasir-VQA-x1 dataset, containing more than 150,000 clinically relevant question–answer pairs, to support the development of AI models that can accurately answer questions based on GI endoscopy images while providing coherent and clinically grounded explanations. The goal is to advance trustworthy and interpretable AI decision support for GI diagnostics.

##### Memorability: Predicting movie and commercial memorability task

The goal of this task is to study the long-term memory performance when recognising small movie excerpts or commercial videos. We provide the videos, precomputed features or EEG features for the challenges proposed in the task such as how memorable a video, if a person is familiar with a video or if you can predict the brand memorability?

##### NewsImages at MediaEval 2026 Retrieval and Generative AI for News Thumbnails

Participants receive a large set of articles (including the headline and article lead) in the English-language from international publishers. We offer two subtasks: retrieving an image for each article from a collection of images that can serve as a thumbnail, or generating an article thumbnail.

##### Synthetic Images: Advancing detection and localization of generative AI used in real-world online images

The goal of this challenge is to develop AI models capable of detecting synthetic images and identifying the specific regions in the images that have been manipulated or synthesized. Approaches will be tested on images synthesized with state-of-the-art approaches and collected from real-world settings online.

