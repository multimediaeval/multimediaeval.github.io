---
layout: edition
title: MediaEval 2025
year: 2025
permalink: /editions/2025/
---

The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data. 
Participants address these challenges by creating algorithms for analyzing, exploring and accessing information in the data. Solutions are systematically compared using a common evaluation procedure, 
making it possible to establish the state of the art and track progress. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.

MediaEval goes beyond other benchmarks and data science challenges in that it also pursues a “Quest for Insight” (Q4I). With Q4I we push beyond only striving to improve evaluation 
scores to also working to achieve deeper understanding about the challenges. For example, properties of the data, strengths and weaknesses of particular types of approaches, and observations 
about the evaluation procedure.

Currently, MediaEval is calling for task proposals, see the call for proposals (link).

Watch here for announcements of the tasks that will be offered in MediaEval 2025.

MediaEval 2025 Schedule:
* Registration for task participation opens: April 2025
* Development data release: May 2025
* Test data release: June 2025
* Runs due: Wed. 24 Sept 2025
* Working notes papers due: Wed. 8 Oct 2025
  
MediaEval 2025 Workshop, Sat.-Sun. 25-26 October 2025, Dublin, Ireland and Online.

<img src="https://multimediaeval.github.io/editions/2020/docs/sigmmlogo.gif" width=150/>
