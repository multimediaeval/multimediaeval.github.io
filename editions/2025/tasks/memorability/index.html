<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Memorability: Predicting movie and commercial memorability | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Memorability: Predicting movie and commercial memorability" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2025 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2025 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2025/tasks/memorability/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2025/tasks/memorability/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-10-24T11:48:33+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Memorability: Predicting movie and commercial memorability" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-10-24T11:48:33+00:00","datePublished":"2025-10-24T11:48:33+00:00","description":"See the MediaEval 2025 webpage for information on how to register and participate.","headline":"Memorability: Predicting movie and commercial memorability","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2025/tasks/memorability/"},"url":"https://multimediaeval.github.io/editions/2025/tasks/memorability/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Memorability: Predicting movie and commercial memorability</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2025/">MediaEval 2025 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task description</h4>

<p>The goal of this task is to study the long-term memory performance when recognizing small movie excerpts or commercial videos. We provide the videos, precomputed features or EEG features for the challenges proposed in the task such as How memorable a video, if a person familiar with a video or if you can predict the brand memorability?</p>

<p><strong>Subtask 1: Movie Memorability</strong>. This task studies the long-term memory performance when recognizing small movie excerpts from weeks to years after having viewed them.</p>
<ul>
  <li><em>Challenge 1.1: How memorable is this video (movie excerpts)?</em> - Video-based prediction: The goal of this task is to predict how memorable a video is based on movie excerpts. Participants are expected to develop automatic systems that predict the memorability scores of new videos. The memorability score indicates the probability of a video being remembered by viewers. To achieve this, participants will use a subset of the Movie Memorability dataset, which includes videos, their corresponding memorability scores.  Participants are free to use only the modalities relevant to their approach, enabling a broad range of methodologies.</li>
  <li><em>Challenge 1.2: Is this person familiar with this video?</em> - EEG-based detection of recall: This task requires participants to automatically detect whether a person is remembering a video from a movie they previously watched. To do this, participants may use only features extracted from the EEG data, without using any features from the videos themselves.</li>
</ul>

<p><strong>Subtask 2: Commercial/Ad Memorability.</strong> This task evaluates long-term memory performance in recognizing commercial videos. Participants will use the VIDEM dataset, which contains commercial videos along with their memorability and brand memorability scores, to train their systems. The trained models will then predict the scores for new, unseen commercial videos (product, brand, and concept presentations and discussions). This challenge does not include EEG data.</p>
<ul>
  <li><em>Challenge 2.1: How memorable is this commercial video?</em> - Video-based prediction: Like in challenge 1.1, the goal of this task is to predict how memorable a commercial video is. Therefore, participants are expected to develop automatic systems that predict the memorability scores of commercial videos. The memorability score indicates the probability of a commercial video being remembered by viewers.</li>
  <li><em>Challenge 2.2: Can you predict the brand memorability?</em> - Video-based prediction: The goal of this task is to predict the brand memorability associated with a commercial video. Participants are expected to develop automatic systems that can predict the brand memorability score based on the content of the commercial video. This score indicates the probability of a commercial video brand being remembered by viewers.</li>
</ul>

<h4 id="motivation-and-background">Motivation and background</h4>

<p>In an era where visual content, such as movies and commercials, permeates our daily lives, understanding and predicting the memorability of multimedia content is becoming increasingly important. For marketers, filmmakers, and content creators, selecting and designing media that effectively captures attention and leaves a lasting impression is crucial for success. Commercials, in particular, need to engage viewers immediately and remain memorable to drive brand recognition and influence consumer behavior. However, the potential applications of memorability prediction extend beyond commercial and advertising sectors.</p>

<p>This task aims to develop models that predict the memorability of multimedia content by leveraging various content features. While the results can directly benefit professionals in advertising and film, the insights gained can also be applied to other fields, such as education, content retrieval, and beyond. For instance, educators can use memorability predictions to create more engaging learning materials, while content retrieval systems can enhance search and recommendation accuracy by prioritizing content with higher memorability potential.</p>

<p>This year’s task extends the state of the art by focusing on the memorability of multimedia content within the specific domains of movies and commercials. While previous research has explored the general memorability of videos and images, there has been limited focus on how this concept applies to the nuanced structure of films and advertisements. By addressing this gap, we aim to deepen our understanding of how human cognition interacts with multimedia, providing valuable insights into what makes content memorable and how it can be optimized for various applications across different industries, including both commercial and non-commercial use cases.</p>

<p><em>New for 2025.</em> 
In 2025, the MediaEval Media Memorability Task introduces two new datasets: the Movie Memorability dataset and the VIDEM dataset. These additions offer exciting opportunities for participants to explore the memorability of movie excerpts and commercial videos across various real-world contexts. This year, the task continues to build on past efforts by integrating multimodal data, including video content, memorability scores, and EEG data collected during memorability experiments, while encouraging innovative approaches to improve prediction accuracy. Additionally, a new challenge is introduced, focusing on brand memorability prediction. In this challenge, participants are not tasked with predicting the memorability of videos but with predicting a brand memorability score for commercial videos. This new challenge seeks to deepen our understanding of how brands are remembered within multimedia content, adding an intriguing layer of complexity to the task.</p>

<h4 id="target-group">Target group</h4>

<p>Researchers interested in this task include those working in areas such as human perception, multimedia content analysis, cognitive science, and machine learning, particularly in the fields of image and video analysis, memorability, emotional response to media, aesthetics, and multimedia affective computing (though not limited to).</p>

<p>This includes scholars focused on predictive modeling, user experience, and the cognitive impact of media, with a specific interest in movies, commercials, and educational content. Signal processing researchers can also bring valuable insights to this task by leveraging EEG signals to enhance the memorability predictive models. Additionally, researchers exploring content retrieval, recommendation systems, and multimedia interaction, as well as those studying the influence of media on memory and learning, will find the task valuable. It will also appeal to those working on improving machine learning algorithms for content classification and understanding, especially in video and image domains, and those interested in applying these models across both commercial and non-commercial media, including educational and informational content.</p>

<h4 id="data">Data</h4>

<p>One dataset will be provided for each subtask.</p>

<p>For subtask 1, a subset of the <a href="https://www.interdigital.com/data_sets/movie-memorability-dataset">Movie Memorability dataset</a> will be used. This is a collection of movie excerpts and corresponding ground-truth files based on the measurement of long-term memory performance when recognizing small movie excerpts from weeks to years after having viewed them. It is accompanied with audio and video features extracted from the movie excerpts. EEG data recorded while viewing this subset will be also provided. EEG data were recorded while 27 participants viewed a subset of clips from the dataset. The clips were selected to include both previously seen and unseen movies. After viewing each clip, participants were asked if they remembered seeing it before. In total 3484 epochs of 64 channel EEG data are available, of which 2122 were not recognised and 1362 were remembered.</p>

<p>For subtask 2, the VIDEM (VIDeo Effectiveness and Memorability) dataset will be used. It focuses on video and brand memorability in commercial advertisements, including some educational or explanatory videos. Developed through a university-business collaboration between the University of Essex and Hub, with support from Innovate UK’s Knowledge Transfer Partnership (grant agreement No. 11071), This is  a collection of commercial advertisements and corresponding ground-truth files based on the measurement of long-term memory performance when recognizing them from 24 to 72 hours after having viewed them.  Each video is accompanied with metadata such as titles, descriptions, number of views, and duration and audio and video features extracted from the commercial advertisements. The dataset consists of 424 commercial videos sampled from a larger collection of 4791 videos published on YouTube between June 2018 and June 2021. Video lengths range from 7 seconds to 94 minutes. For longer videos, users are allowed to watch only 1 minute.</p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>

<p>Submissions for the video-based prediction challenges will be evaluated using Spearman’s rank correlation coefficient. Additional metrics, such as Mean Squared Error (MSE), may also be used to assess prediction accuracy.
For Challenge 1.2 (EEG-based detection of recall), submissions will be evaluated based on accuracy.</p>

<h4 id="quest-for-insight">Quest for insight</h4>

<p>Here are several research questions related to this challenge that participants can strive to answer in order to go beyond just looking at the evaluation metrics:</p>
<ul>
  <li>How do factors like the emotional content, subject matter, or cultural context of media influence its memorability?</li>
  <li>How well do machine-predicted memorability scores align with human cognitive processes involved in memory formation?</li>
  <li>Is there a relationship between the aesthetic quality of media and its memorability, or do these factors function independently?</li>
  <li>Is there a difference between what causes memory recall in movie clips versus what causes memory recall in commercial videos?</li>
  <li>What transformations or enhancements can be applied to media content to increase its memorability without altering its core message?</li>
  <li>Which EEG signals (e.g., specific frequency bands or event-related potentials) are most predictive of media memorability?</li>
  <li>To what extent do EEG patterns associated with memorable media generalize across different individuals?</li>
</ul>

<h4 id="participant-information">Participant information</h4>

<p>More details will follow.</p>

<!-- Please contact your task organizers with any questions on these points. -->
<!-- # * Signing up: Fill in the [registration form]() and fill out and return the [usage agreement](). -->
<!-- # * Making your submission: To be announced (check the task read me) <!-- Please add instructions on how to create and submit runs to your task replacing "To be announced." -->
<!-- # * Preparing your working notes paper: Instructions on preparing you working notes paper can be found in [MediaEval 2023 Working Notes Paper Instructions]().-->

<h4 id="references-and-recommended-reading">References and recommended reading</h4>

<p>[1] 2018 R.Cohendet, K. Yadati, N. Q. Duong and C.-H. Demarty. <a href="https://dl.acm.org/doi/abs/10.1145/3206025.3206056">Annotating, understanding, and predicting long-term video memorability</a>. In Proceedings of the ICMR 2018 Conference, Yokohama, Japan, June 11-14, 2018.</p>

<p>[2] 2025. R. S. Kiziltepe, S. Sahab, R. Valladares Santana, F. Doctor, K. Paterson, D. Hunstone and A. García Seco de Herrera. VIDEM: VIDeo Effectiveness and Memorability Dataset. In Proceedings of the 18th International Work-Conference on Artificial Neural Networks (IWANN 2025), A Coruña, Spain, June 16–18, 2025.</p>

<p>[3] 2014. Phillip Isola, Jianxiong Xiao, Devi Parikh, Antonio Torralba, and Aude Oliva. <a href="https://ieeexplore.ieee.org/document/6629991/">What makes a photograph memorable?</a> IEEE Transactions on Pattern Analysis and Machine Intelligence 36, 7 (2014), 1469–1482.</p>

<p>[4] 2023. Dumont, T., Hevia, J. S., &amp; Fosco, C. L. <a href="https://openaccess.thecvf.com/content/CVPR2023/papers/Dumont_Modular_Memorability_Tiered_Representations_for_Video_Memorability_Prediction_CVPR_2023_paper.pdf">Modular memorability. Tiered representations for video memorability prediction.</a> In Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition (pp. 10751-10760).</p>

<p>[5] 2025. Kumar, P. et al. <a href="https://arxiv.org/pdf/2311.16484">Eye vs. AI: Human Gaze and Model Attention in Video Memorability.</a> In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Tucson, AR, USA, 2025.</p>

<p>[6] 2025. SI, H.et al. <a href="https://arxiv.org/pdf/2309.00378">Long-Term Memorability On Advertisements.</a> In Proceedings of the IEEE/CVF Winter Conference on Applications of Computer Vision (WACV), Tucson, AR, USA, 2025.</p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Alba García Seco de Herrera,  National University of Distance Education (UNED), Spain (main organizer) - alba.garcia@lsi.uned.es</li>
  <li>Sebastian Halder, Ana Matran-Fernandez, University of Essex, UK;</li>
  <li>Mihai Gabriel Constantin, Bogdan Ionescu, National University of Science and Technology Politehnica Bucharest, Romania;</li>
  <li>Claire-Hélène Demarty, InterDigital, R&amp;I, France;</li>
  <li>Rukiye Savran Kiziltepe, Ankara University, Türkiye;</li>
  <li>Iván Martín-Fernández, Manuel Gil-Martín, Technical University of Madrid (UPM), Spain</li>
</ul>

<h4 id="task-schedule">Task schedule</h4>

<p>The program will be updated with the exact dates.</p>

<ul>
  <li>May 2025: Development Data release <!-- * XX May 2025: Data release <!-- # Replace XX with your date. We suggest setting the date in May - of course if you want to realease sooner it's OK. --></li>
  <li>June 2025: Testing Data release <!-- * XX June 2025: Data release <!-- # Replace XX with your date. We suggest setting the date in June - of course if you want to realease sooner it's OK. --></li>
  <li>01 October 2025: Runs due and results returned. (we extended the deadline) <!--* XX September 2025: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned.--></li>
  <li>08 October 2025: Working notes paper  <!-- Fixed. Please do not change.--></li>
  <li>25-26 October 2025: MediaEval Workshop, Dublin, Ireland and Online.. <!-- Fixed. Please do not change.--></li>
</ul>

<h4 id="acknowledgements">Acknowledgements</h4>

<p>More details will follow.</p>

<!-- # optional, delete if not used-->


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
