<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>MediaEval 2021 | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="MediaEval 2021" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The MediaEval Multimedia Evaluation benchmark offers tasks that are related to multimedia retrieval, analysis, and exploration. Participation is open to interested researchers who register. MediaEval focuses specifically on the human and social aspects of multimedia, and on multimedia systems that serve users. MediaEval tasks offer the opportunity for researchers to tackle challenges that bring together multiple modalities (visual, text, music, sensor data)." />
<meta property="og:description" content="The MediaEval Multimedia Evaluation benchmark offers tasks that are related to multimedia retrieval, analysis, and exploration. Participation is open to interested researchers who register. MediaEval focuses specifically on the human and social aspects of multimedia, and on multimedia systems that serve users. MediaEval tasks offer the opportunity for researchers to tackle challenges that bring together multiple modalities (visual, text, music, sensor data)." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-06-23T06:52:23+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","url":"https://multimediaeval.github.io/editions/2021/","headline":"MediaEval 2021","dateModified":"2022-06-23T06:52:23+00:00","datePublished":"2022-06-23T06:52:23+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/"},"description":"The MediaEval Multimedia Evaluation benchmark offers tasks that are related to multimedia retrieval, analysis, and exploration. Participation is open to interested researchers who register. MediaEval focuses specifically on the human and social aspects of multimedia, and on multimedia systems that serve users. MediaEval tasks offer the opportunity for researchers to tackle challenges that bring together multiple modalities (visual, text, music, sensor data).","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>MediaEval 2021</h2>
  </header>

  <p>The MediaEval Multimedia Evaluation benchmark offers tasks that are related to multimedia retrieval, analysis, and exploration. Participation is open to interested researchers who register. MediaEval focuses specifically on the human and social aspects of multimedia, and on multimedia systems that serve users. MediaEval tasks offer the opportunity for researchers to tackle challenges that bring together multiple modalities (visual, text, music, sensor data).</p>

<!-- 
### Registration
Register to participate at [MediaEval 2021 Registration](https://docs.google.com/forms/d/e/1FAIpQLSchIcIaSlM1fNeWGCSoSBMR6HS48HKMhWEY151vvCmb5KhO-w/viewform?usp=sf_link) Participation is open to anyone who registers. 

Once you have registered you will be asked to return the [MediaEval 2021 Usage Agreement](https://multimediaeval.github.io/editions/2021/docs/MediaEval2021_UsageAgreement.pdf) (and possibly another task-specific agreement depending on the task that you register for). Please follow the directions carefully.
-->

<h3 id="workshop">Workshop</h3>

<!-- * Register for the workshop here: [MediaEval 2021 Workshop Registration Form](https://multimediaeval.github.io/editions/2021/docs/MediaEval2021WorkshopScheduleAndThanks.pdf) -->
<ul>
  <li>Workshop schedule is here: <a href="https://multimediaeval.github.io/editions/2021/docs/MediaEval2021WorkshopScheduleAndThanks.pdf">MediaEval 2021 Workshop Program</a></li>
  <li>Proceedings: <a href="https://2021.multimediaeval.com/">MediaEval 2021 Preliminary Working Notes Proceedings</a></li>
  <li>Video of Workshop Overview: <a href="https://www.youtube.com/watch?v=h45gydsoM1M">Opening presentation 13 Dec 2021</a></li>
</ul>

<p>Workshop group photo:</p>

<p><img src="https://multimediaeval.github.io/editions/2020/docs/MediaEval2021GroupPhoto.png" width="300" /></p>

<!-- * #### Attendee workshop information
* The MediaEval 2021 Workshop will be held completely online this year and participation is free. However, you are required to register in order to attend. If multiple people from one team will be participating in the workshop, then each one needs to register. 
* On Monday, Tuesday and Wednesday 13-15 December (14:00-18:30 Central European Time) we have different types of sessions:
  * Opening session: Starts at 14:00 CET on 13 December and will give you an overview of all tasks and importat workshop information. (Zoom)
  * Presentation sessions: Begin with an overview talk introducing the task. Then, each participant presents a three minute introduction of their task. The talks are live, and followed by questions and answers. (Zoom)
  * Technical retreat sessions: Discussion sessions where organizers and participants exchange experiences on the task and discuss plans for future work. (Discord)
<!-- * The exact workshop schedule will be published here in the days before the workshop.
* Just before the workshop, you will receive by email the links to the workshop platforms.
-->

<!-- #### Time Slots for Presentations (may change):

**Day 1: Monday 13 December 14:00-18:30 CET:**
* WaterMM: Water Quality in Social Multimedia - 15:00 - 15:45
* Emerging News: Detecting emerging stories from social media and news feeds - 15:00 - 15:45
* Emotional Mario: Believable AI agents in video games - 15:00 - 15:45
* Emotions and Themes in Music - 15:00 - 15:45
* Sports Video: Fine Grained Action Detection and Classification of Table Tennis Strokes from videos - 16:15 - 17:00
* Visual Sentiment Analysis: A Natural Disaster Use-case - 16:15 - 17:00

**Day 2: Tuesday 14 December 14:00-18:30 CET**
* NewsImages: The relation between images and text in news articles - 15:15 - 16:15
* Medico: Transparency in Medical Image Segmentation - 15:15 - 16:15

**Day 3: Wednesday 15 December 14:00-18:30 CET**
* FakeNews: Corona virus and 5G conspiracy - 14:00 - 16:15
* Predicting Media Memorability - 15:15 - 16:15
* Insight for Wellbeing: Cross-Data Analytics for (transboundary) Haze Prediction - 14:00 - 15:00
* Driving Road Safety Forward: Video Data Privacy - 17:45 - 18:00

#### Time Slots for Technical Retreats (may change):
**Day 1: Monday 13 December 14:00-18:30 CET**
* WaterMM: Water Quality in Social Multimedia - 17:15 - 18:15
* Emerging News: Detecting emerging stories from social media and news feeds - 17:15 - 18:15
* Emotional Mario: Believable AI agents in video games - 17:15 - 18:15
* Emotions and Themes in Music - 17:15 - 18:15

**Day 2: Tuesday 14 December 14:00-18:30 CET**
* Sports Video: Fine Grained Action Detection and Classification of Table Tennis Strokes from videos - 14:00 - 15:00
* Visual Sentiment Analysis: A Natural Disaster Use-case - 14:00 - 15:00
* NewsImages: The relation between images and text in news articles - 16:45 - 17:45
* Medico: Transparency in Medical Image Segmentation - 16:45 - 17:45

**Day 3: Wednesday 15 December 14:00-18:30 CET**
* FakeNews: Corona virus and 5G conspiracy - 16:30 - 17:30
* Predicting Media Memorability - 16:30 - 17:30
* Insight for Wellbeing: Cross-Data Analytics for (transboundary) Haze Prediction - 16:30 - 17:30
-->

<h3 id="important-dates-updated">Important Dates (Updated)</h3>
<ul>
  <li>July-September 2021: Data releases</li>
  <li>Mid-November 2021: Runs due (See individual task pages for the exact deadlines)</li>
  <li>29 November 2021: Working notes paper due</li>
  <li>9 December 2021: Video and workshop-ready paper due</li>
  <li>13-15 December 2021: MediaEval 2021 Workshop Online (The workshop will be held during the “Golden Hours” 14:00-18:30 UTC+1)</li>
</ul>

<h4 id="the-mediaeval-organization">The MediaEval Organization</h4>
<p>MediaEval is made possible by the efforts of a larger number of task organizers, who each are responsible for organizing their own tasks. Please see the individual task pages for their name. The over all organization is carried out by the MediaEval Coorindation Committe and guided by the Community Council.</p>

<h5 id="the-mediaeval-coordination-committee-2021">The MediaEval Coordination Committee (2021)</h5>
<ul>
  <li>Mihai Gabriel Constantin, University Politehnica of Bucharest, Romania</li>
  <li>Steven Hicks, SimulaMet, Norway</li>
  <li>Martha Larson, Radboud University, Netherlands (Overall coordinator and main contact person)</li>
</ul>

<h5 id="special-thanks-to">Special Thanks to</h5>
<ul>
  <li>Ngoc-Thanh Nguyen, University of Information Technology, Vietnam</li>
  <li>Ricardo Manhães Savii, Dafiti Group, Brasil (Website)</li>
</ul>

<h5 id="the-mediaeval-community-council-2021">The MediaEval Community Council (2021)</h5>
<ul>
  <li>Martha Larson, Radboud University, Netherlands (Coordinator and contact person)</li>
  <li>Gareth J. F. Jones, Dublin City University, Dublin, Ireland</li>
  <li>Bogdan Ionescu, University Politehnica of Bucharest, Romania</li>
</ul>

<p>MediaEval is grateful for the support of <a href="http://sigmm.org/">ACM Special Interest Group on Multimedia</a></p>

<p><img src="https://multimediaeval.github.io/editions/2020/docs/sigmmlogo.gif" width="150" /></p>

<p>For more information, contact m.larson (at) ru.cs.nl. You can also follow us on Twitter @multimediaeval</p>

  
  

  
  <h3>
    Task List
  </h3>

  
  <ul class="right hide-on-med-and-down"></ul>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/"><h4>Driving Road Safety Forward: Video Data Privacy</h4></a>
    <p>This task aims to explore methods for obscuring driver identity in driver-facing video recordings while preserving human behavioral information.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/emergingnews/"><h4>Emerging News: Detecting emerging stories from social media and news feeds</h4></a>
    <p>Emerging News task aims to explore novel ways to detect emerging stories from semantic streams of social media messages and news feeds.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/emergingnews/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/"><h4>Emotional Mario: A Games Analytics Challenge</h4></a>
    <p>Carry out analysis of emotion on videos and biometric data of players to predict key events in the gameplay. Optionally, use these predictions to create a highlights video containing the best moments of gameplay.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/music/"><h4>Emotions and Themes in Music</h4></a>
    <p>We invite the participants to try their skills in building a classifier to predict the emotions and themes conveyed in a music recording, using our dataset of music audio, pre-computed audio features, and tag annotations (e.g., happy, sad, melancholic). All data we provide comes from Jamendo, an online platform for music under Creative Commons licenses.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/music/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/fakenews/"><h4>FakeNews: Corona Virus and Conspiracies Multimedia Analysis Task</h4></a>
    <p>The FakeNews task explores various machine-learning approaches to automatically detect misinformation and its spreaders in social networks.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/fakenews/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/wellbeing/"><h4>Insight for Wellbeing: Cross-Data Analytics for (transboundary) Haze Prediction</h4></a>
    <p>The task is organized as multiple subtasks to encourage multi-disciplinary research to consider additional data sources (cross-data) to improve prediction and/or find insights for wellbeing based on environmental factors, satellite remote sensing, social/news data, etc. The problems this task tries to tackle are "air pollution" and "transboundary haze".</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/wellbeing/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/medico/"><h4>Medico: Transparency in Medical Image Segmentation</h4></a>
    <p>The Medico task explores the use of transparent approaches to automatically segment images collected from the human colon.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/medico/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/newsimages/"><h4>NewsImages</h4></a>
    <p>Images play an important role in online news articles and news consumption patterns. This task aims to achieve additional insight about this role. Participants are supplied with a large set of articles (including text body, and headlines) and the accompanying images. The task requires participants to predict which image was used to accompany each article and also predict frequently clicked articles on the basis of accompanying images.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/newsimages/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/memorability/"><h4>Predicting Media Memorability</h4></a>
    <p>The task requires participants to automatically predict memorability scores for videos, that reflect the probability for a video to be remembered. Participants will be provided with an extensive data set of videos with memorability annotations, related information, and pre-extracted state-of-the-art visual features.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/memorability/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/sportsvideo/"><h4>Sports Video: Fine Grained Action Detection and Classification of Table Tennis Strokes from videos</h4></a>
    <p>Participants are provided with a set of videos of table tennis games and are required to analyze them (i.e., carry out classification and detection of strokes). The ultimate goal of this research is to produce automatic annotation tools for sports faculties, local clubs and associations to help coaches to better assess and advise athletes during training.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/sportsvideo/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/"><h4>Visual Sentiment Analysis: A Natural Disaster Use-case</h4></a>
    <p>The Visual Sentiment Analysis task aims at finding methods that can predict the emotional response from disaster-related images.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2021/tasks/watermm/"><h4>WaterMM: Water Quality in Social Multimedia</h4></a>
    <p>The quality of drinking water can have a direct effect on the health of people. In this task, the participants are asked to automatically determine which social media posts (i.e., tweets) are relevant to water quality, safety and security, by using their text, images and metadata. The dataset is bilingual (i.e., English and Italian tweets), while the ground truth labels have been provided by experts in the water domain.</p>
    <a href="https://multimediaeval.github.io/editions/2021/tasks/watermm/">Read more.</a>
    <br>
  
</ul>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
