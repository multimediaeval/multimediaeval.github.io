<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Emotional Mario: A Games Analytics Challenge | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="Emotional Mario: A Games Analytics Challenge" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-07-24T18:43:53+00:00" />
<script type="application/ld+json">
{"@type":"BlogPosting","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","url":"https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/","headline":"Emotional Mario: A Games Analytics Challenge","dateModified":"2022-07-24T18:43:53+00:00","datePublished":"2022-07-24T18:43:53+00:00","description":"See the MediaEval 2021 webpage for information on how to register and participate.","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/emotionalmario/"},"@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Emotional Mario: A Games Analytics Challenge</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>In this task, participants carry out multimedia analysis in order to gain insight into the emotion of players playing video games. The task is called <em>Emotional Mario</em> because it focuses on the iconic video game Super Mario Bros.</p>

<p><strong><em>Subtask 1: Event Detection:</em></strong> Participants carry out emotional anlaysis on facial videos and biometric data (e.g., heart rate and skin conductivity) collected from players playing the game. The goal is to identify key events (i.e., events of high significance in the gameplay). Such key events include <em>the end of a level</em>, a <em>power-up</em> or <em>extra life for Mario</em>, or <em>Mario’s death</em>.</p>

<p><strong><em>Subtask 2: Gameplay Summarization (Optional):</em></strong> Participants create a video summary of the best moments of the play. This can include gameplay scenes, facial video, data visualization, and whatever comes to your mind that you find important to tell the <em>game story</em>, the story of what happened during the game.</p>

<!-- <img src="https://raw.githubusercontent.com/multimediaeval/multimediaeval.github.io/gh-page/_editions/2021/docs/me21_emo_mario.jpg" alt="Emotional Mario gameplay screen shot"/> -->

<p>Subtask 1 is a technical task, and easily approachable. Subtask 2 is an open, creative task, which builds on event detection. Past experience has shown that it is easier to step into the task with a technical subtask, and use that as inspiration for the creative task. The ultimate goal of the Emotional Mario task is to develop new approaches to the creative task of telling the story of a game.
<em>Participants are encouraged to make their code public with their submission.</em></p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>As games are designed to evoke emotions [1], we hypothesize that emotions in the player are reflected in the visuals of the video game. Simple examples are when players are happy after having mastered a particularly complicated challenge, when they are shocked by a jump scare scene in a horror game, or when they are excited after unlocking a new resource. These things can be measured by questionnaires after playing [2], but in the Emotional Mario task, we want to interconnect emotions and gameplay based on data instead of asking the players.</p>

<p>With the rise of deep learning, many large leaps in research have been achieved in recent years such as human-level image recognition, text classification, and even content creation. Games and deep learning also have a rather long history together, specifically in the context of reinforcement learning. However, video games still pose a lot of challenges. Games are understood as engines of experience [1], and as such, they need to invoke human emotions. While emotion recognition has come a far way over the last decade [3], the connection between emotions and video games is still an open and interesting research question. In the Emotional Mario task, we aim to leverage deep learning to move forward our understanding of the role of emotions in video games</p>

<h4 id="target-group">Target group</h4>
<p>The target group for this task is diverse and broad. It includes researchers and practitioners from game design and development, game studies, machine learning, artificial intelligence, and interactive multimedia. We also encourage interdisciplinary research involving people from psychology, game studies, and the humanities discussing the interrelation of biometric data, facial expressions, and gameplay. In any case, regardless of the research background, the submission will help to have a basic understanding of how we can better understand the connection between gameplay and the reaction of the player.</p>

<h4 id="data">Data</h4>
<p>For the EmotionalMario challenge, we focus on the iconic Super Mario Bros. video game and provide a multimodal data set based on a Super Mario Bros. implementation for OpenAI Gym. The data set, called Toadstool [4], contains for a population of ten players their game input, demographics, biomedical sensory input from a medical-grade device (e.g., heart rate and skin conductivity) as well as videos of their faces while playing the game. The data set also contains he gameplay itself, demographics on the players and their scores and times spent in the game.he gameplay itself, demographics on the players and their scores and times spent in the game.</p>

<p>Additionally, we provide ground truth for special events within the gameplay for eight of the study participants. We extracted the data from the gameplay session file. The remaining two serve as data for the runs to be submitted.</p>

<p>The toadstool data is available from <a href="https://osf.io/qrkcf/">https://osf.io/qrkcf/</a> and the ground truth can be downloaded from [https://www.itec.aau.at/~mlux/files/EmotionalMario2021_Training_Data.zip](https://www.itec.aau.at/~mlux/files/EmotionalMario2021_Training_Data.zip). For a head start we’ve done an analysis with <a href="https://github.com/justinshenk/fer">FER</a> of the facial videos. You can find the result <a href="https://drive.google.com/drive/folders/1L2kYwcmYDFuALLGdI5vHgOLESMCS6EJ_?usp=sharing">here</a>.</p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>

<p><strong><em>Subtask 1: Event Detection:</em></strong> In this subtask, participants identify events in the gameplay by making use of biometric data and videos of facial expressions. These events include player deaths, obtaining power-ups, and completing a level. Ground truth as well as an evaluation script will be provided. 
We also encourage participants to carry out a failure analysis of their results in order to gain insight in the mistakes that their classifiers make.</p>

<p><strong><em>Subtask 2: Gameplay Summarization:</em></strong> In this subtask, participants are asked to submit a summary video for a study participant from the Toadstool data. There is no constraint on the modalities of the story, so it can be video, audio, text, images, or a combination thereof. An expert panel with  professionals and researchers from the field of game development, game studies, e-sports, and media sciences will then investigate the submissions and judge them for:</p>
<ul>
  <li>Informative value (i.e. is it a good summary of the gameplay),</li>
  <li>Accuracy (i.e. does it reflect the emotional up and downs and the skill of the play), and</li>
  <li>Innovation (ie. surprisingly new approach, non-linearity of the story, creative use of cuts, etc.)</li>
</ul>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>

<p>[1] Tynan Sylvester. 2013. <a href="https://www.oreilly.com/library/view/designing-games/9781449338015/">Designing games: A guide to engineering experiences</a>. O’Reilly Media, Inc.</p>

<p>[2] Abeele, V. V., Spiel, K., Nacke, L., Johnson, D., and Gerling, K. 2020. <a href="https://lirias.kuleuven.be/retrieve/580761">Development and validation of the player experience inventory: A scale to measure player experiences at the level of functional and psychosocial consequences</a>. International Journal of Human-Computer Studies, 135, 102370.</p>

<p>[3] Saxena, Anvita, Ashish Khanna, and Deepak Gupta. 2020. <a href="https://iecscience.org/uploads/jpapers/202003/dnQToaqdF8IRjhE62pfIovCkDJ2jXAcZdK6KHRzM.pdf">Emotion recognition and detection methods: A comprehensive survey.</a> Journal of Artificial Intelligence and Systems 2.1 (2020): 53-79.</p>

<p>[4] Henrik Svoren, Vajira Thambawita, Pål Halvorsen, Petter Jakobsen, Enrique Garcia-Ceja, Farzan Majeed Noori, Hugo L. Hammer, Mathias Lux, Michael Alexander Riegler, and Steven Alexander Hicks. 2020. <a href="https://dl.acm.org/doi/abs/10.1145/3339825.3394939">Toadstool: A Dataset for Training Emotional Intelligent Machines Playing Super Mario Bros.</a> In Proceedings of the 11th ACM Multimedia Systems Conference (MMSys ’20). Association for Computing Machinery, New York, NY, USA, 309–314.</p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Mathias Lux (Alpen-Adria-Universität Klagenfurt, AT; mathias.lux@aau.at)</li>
  <li>Michael Riegler, Pål Halvorsen, Vajira Thambawita, and Steven Hicks (SimulaMet Oslo, NO)</li>
  <li>Duc-Tien Dang-Nguyen and Kristine Jorgensen (University of Bergen, NO)</li>
</ul>

<h4 id="task-schedule-updated">Task Schedule (Updated)</h4>
<ul>
  <li>13 July: Data release</li>
  <li>14 November: Runs due</li>
  <li>22 November: Results returned</li>
  <li>29 November: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>13-15 December 2021: MediaEval 2021 Workshop Online <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>



      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
