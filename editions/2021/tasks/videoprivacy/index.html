<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Driving Road Safety Forward: Video Data Privacy | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Driving Road Safety Forward: Video Data Privacy" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="*See the MediaEval 2021 webpage for information on how to register and participate. In addition, register here to access data from the GitHub repository and receive announcements about Jupyter Notebook tutorials, team formation, and seed funding opportunities. *" />
<meta property="og:description" content="*See the MediaEval 2021 webpage for information on how to register and participate. In addition, register here to access data from the GitHub repository and receive announcements about Jupyter Notebook tutorials, team formation, and seed funding opportunities. *" />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-06-12T11:01:14+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Driving Road Safety Forward: Video Data Privacy" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-06-12T11:01:14+00:00","datePublished":"2023-06-12T11:01:14+00:00","description":"*See the MediaEval 2021 webpage for information on how to register and participate. In addition, register here to access data from the GitHub repository and receive announcements about Jupyter Notebook tutorials, team formation, and seed funding opportunities. *","headline":"Driving Road Safety Forward: Video Data Privacy","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/"},"url":"https://multimediaeval.github.io/editions/2021/tasks/videoprivacy/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2023/" style="color:white;">MediaEval 2023</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2023/" style="color:white;">MediaEval 2023</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Driving Road Safety Forward: Video Data Privacy</h2>
  </header>

  <!-- # please respect the structure below-->
<p>*See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate. In addition, <a href="https://bit.ly/VideoDataPrivacy">register here</a> to access data from the GitHub repository and receive announcements about Jupyter Notebook tutorials, team formation, and seed funding opportunities. *</p>

<h4 id="task-description">Task Description</h4>
<p>The goal of this video data task is to explore methods for obscuring driver identity in driver-facing video recordings while preserving human behavioral information.</p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>The lifetime odds for dying in a car crash are 1 in 107 [1]. Each year, vehicle crashes cost hundreds of billions of dollars [2]. Research shows that driver behavior is a primary factor in â…” of crashes and a contributing factor in 90% of crashes [3].</p>

<p>Video footage from driver-facing cameras presents a unique opportunity to study driver behavior.  Indeed, in the United States, the Second Strategic Highway Research Program (SHRP2) worked with drivers across the country to collect more than 1 million hours of driver video [4, 5]. Moreover, the growth of both sensor technologies and computational capacity provides new avenues for exploration.</p>

<p>However, video data analysis and interpretation related to identifiable human subjects bring forward a variety of multifaceted questions and concerns, spanning privacy, security, bias, and additional implications [6]. This task aims to advance the state-of-the-art in video de-identification, encouraging participants from all sectors to develop and demonstrate techniques with the provided data. Successful methods balancing driver privacy with fidelity of relevant information have the potential to not only broaden researcher access to existing data, but also inform the trajectory of transportation safety research, policy, and education initiatives [7].</p>

<h4 id="target-group">Target group</h4>
<p>Participants of all experience levels and backgrounds with interests including de-identification techniques, video analytics, transportation safety, security, privacy, human behavior, and risk assessment are invited to engage in and contribute to this task. From expert researchers in academia and industry to students, nonprofit organizations, and government, all are encouraged to explore the data and submit approaches and technical demonstrations of driver de-identification.</p>

<h4 id="data">Data</h4>
<p>The dataset consists of both high- and low-resolution driver video data prepared by Oak Ridge National Laboratory for this Driver Video Privacy Task. The data were captured using the same data acquisition system as the larger SHRP2 dataset mentioned above, which currently has limited access in a secure enclave. For the data in this Task, there are drivers in choreographed situations designed to emulate different naturalistic driving environments. Actions include talking, coughing, singing, dancing, waving, eating, and various others [8]. Through this unique partnership, annotated data from Oak Ridge National Laboratory will be available to registered participants, alongside experts from the data collection and processing team who will be available for mentoring and any questions.</p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p>The evaluation process includes a preliminary automated evaluation as well as a human evaluation, to assess the de-identification of faces and measure the consistency in preserving driver actions and emotions. An initial automated process will be run using a deep learning-based gaze estimator. The difference in predicted gaze-vectors from the original un-filtered video and de-identified video will be used as an initial score. Human evaluators will use the evaluation methodology as described by Baragchizadeh et al. in Evaluation of Automated Identity Masking Method (AIM) in Naturalistic Driving Study (NDS) [9].</p>

<p>The scores for each of these areas will be combined for an overall assessment, prioritizing the human assessment of de-identification. PLEASE NOTE that this Task is heavily reliant on human evaluation, and we encourage participants to include in their submission any ideas, methods, and results from their own evaluation approaches. The participantsâ€™ descriptions of methodology, assumptions, and results will be shared with reviewers and the project organizers for additional discussion and opportunities for seed funding for further research.</p>

<p>Although we encourage all Task participants to think creatively and holistically about how the expectations of privacy, the risk from potential attackers, and various threat models may evolve, our starting assumptions are that: 
(1) The drivers are not known to the potential attacker. We assume there is no relationship between the attacker and the driver. Furthermore, it is assumed that the driver is not a public figure. 
(2) Any information from the driverâ€™s surroundings is assumed to not influence the attackerâ€™s ability to identify the driver. 
(3) Access to the data is limited to registered users who have signed a Data Use Agreement specifying they will not attempt to learn the identity of individuals in the videos. 
(4) Attackers have access to basic computational resources. 
(5) There is a low probability of attackers launching an effective crowdsourcing strategy to re-identify the drivers, in part due to the Data Use Agreement and context in which the data were collected.</p>

<p>The organizers of this Task encourage open source code with a MIT license, and the open sharing of insights to support a multidisciplinary community of practice. We anticipate that with the engagement of the MediaEval community there will be multiple opportunities to highlight both quantitative and qualitative feedback from participants, supporting reproducibility, open science, and future collaborative research.</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->

<p>[1] Odds of dying. (2021, March 04). Retrieved March 28, 2021, from    https://injuryfacts.nsc.org/all-injuries/preventable-death-overview/odds-of-dying/</p>

<p>[2] Blincoe, L. J., Miller, T. R., Zaloshnja, E., &amp; Lawrence, B. A. (2015, May). The economic and societal impact of motor vehicle crashes, 2010. (Revised)(Report No. DOT HS 812 013). Washington, DC: National Highway Traffic Safety Administration.</p>

<p>[3] Dingus, T., Guo, F., Lee, S., Antin, J., Perez, M., Buchanan-King, M., &amp; Hankey, J. (2016,  March 08). Driver crash risk factors and prevalence evaluation using naturalistic driving data. Retrieved April 18, 2021, from https://www.pnas.org/content/113/10/2636</p>

<p>[4] About safety Data: Strategic Highway research Program 2 (SHRP 2). Retrieved from                      http://www.trb.org/StrategicHighwayResearchProgram2SHRP2/SHRP2DataSafetyAbout.aspx</p>

<p>[5] A Brief Look at the History of SHRP2     http://shrp2.transportation.org/pages/History-of-SHRP2.aspx</p>

<p>[6] Finch, K. (2016, April 25). A visual guide to practical data de-identification. Retrieved March 28, 2021, from https://fpf.org/blog/a-visual-guide-to-practical-data-de-identification/</p>

<p>[7] Exploratory Advanced Research Program Video Analytics Research Projects https://www.fhwa.dot.gov/publications/research/ear/15025/15025.pdf</p>

<p>[8] Ferrell, R., Aykac, D., Karnowski, T., &amp; Srinivas, N. (2021, January). A Publicly Available, Annotated Data Set for Naturalistic Driving Study and Computer Vision Algorithm Development. Retrieved from https://info.ornl.gov/sites/publications/Files/Pub122418.pdf</p>

<p>[9] Baragchizadeh, Asal, Oâ€™Toole, Alice, Karnowski, Thomas Paul, &amp; Bolme, David S. Evaluation of Automated Identity Masking Method (AIM) in Naturalistic Driving Study (NDS). United States. https://doi.org/10.1109/FG.2017.54</p>

<h4 id="task-organizers">Task organizers</h4>
<p>Please get in touch. Experts from the data collection and processing team are available for mentoring and any questions. We will be updating the information below throughout the summer.</p>

<ul>
  <li>Meredith Lee, University of California, Berkeley, USA mmlee (at) berkeley.edu</li>
  <li>Gerald Friedland, University of California, Berkeley, USA  fractor (at) berkeley.edu</li>
  <li>Alex Liu, University of California, Berkeley, USA  alexshiyuliu (at) berkeley.edu</li>
  <li>Andrew Boka, University of California, Berkeley, USA</li>
  <li>Arjun Sarup, University of California, Berkeley, USA</li>
</ul>

<!--#### Task auxiliaries -->
<!-- # optional, delete if not used-->
<!-- # First auxiliary-->
<!-- # Second auxiliary-->
<!-- # and so on-->

<h4 id="task-schedule-updated">Task Schedule (Updated)</h4>
<ul>
  <li>July 2021: Registration on Submittable opens</li>
  <li>July 2021: Data release to registered participants <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>August-October 2021: Community webinars/mentoring</li>
  <li>15 November 2021: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>23 November 2021: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>1 December 2021: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>13-15 December 2021: MediaEval 2021 Workshop <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>

<h4 id="acknowledgments">Acknowledgments</h4>
<p>Special thanks to our collaborators, advisors, and mentors, including:</p>

<p>Asal Baragchizadeh, School of Behavior and Brain Science, The University of Texas at Dallas<br />
Alice Oâ€™Toole, School of Behavior and Brain Science, The University of Texas at Dallas<br />
Thomas P. Karnowski, Oak Ridge National Laboratory<br />
Regina Ferrell, Oak Ridge National Laboratory<br />
Charles Fay, U.S. Department of Transportation, Federal Highway Administration<br />
David Kuehn, U.S. Department of Transportation, Federal Highway Administration<br />
as well as Natalie Evans Harris, Lauren Smith, RenÃ© BastÃ³n, David E. Culler, and the NSF Big Data Hubs network</p>

<p>This effort is made possible through community volunteers and National Science Foundation Grants 1916573, 1916481, and 1915774.
<!-- # optional, delete if not used--></p>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the â€˜multiâ€™ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
