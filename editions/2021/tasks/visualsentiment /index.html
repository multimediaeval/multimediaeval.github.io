<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Visual Sentiment Analysis: A Natural Disaster Use-case | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Visual Sentiment Analysis: A Natural Disaster Use-case" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-04-01T16:08:52+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Visual Sentiment Analysis: A Natural Disaster Use-case" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-04-01T16:08:52+00:00","datePublished":"2025-04-01T16:08:52+00:00","description":"See the MediaEval 2021 webpage for information on how to register and participate.","headline":"Visual Sentiment Analysis: A Natural Disaster Use-case","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/"},"url":"https://multimediaeval.github.io/editions/2021/tasks/visualsentiment%20/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Visual Sentiment Analysis: A Natural Disaster Use-case</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>Disaster-related images are complex and often evoke an emotional response, both good and bad. This task focuses on performing visual sentiment analysis on images collected from disasters across the world. 
<!-- # Here you need a short sentence so that people know that it is the sentiment expressed by the photographer as judged by crowdsourcing workers-->
The images contained in the provided dataset aim to provoke an emotional response through both intentional framining and based on the contents itself.</p>

<p><em>Subtask 1: Single-label Image Classification</em> The first task aims at a single-label image classification task, where the images are arranged in three different classes, namely positive, negative, and neutral with a bias towards the negative samples, due to the topic taken into consideration.</p>

<p><em>Subtask 2: Multi-label Image Classification</em> This is a multi-label image classification task where the participants will be provided with multi-labeled images. The multi-label classification strategy, which assigns multiple labels to an image, better suits our visual sentiment classification problem and is intended to show the correlation of different sentiments. In this task seven classes, namely joy, sadness, fear, disgust, anger, surprise, and neutral, are covered.</p>

<p><em>Subtask 3: Multi-label Image Classification</em> The task is also a multi-label, however, a wider range of sentiment classes are covered. Going deeper in the sentiment hierarchy, the complexity of the task increases.  The sentiment categories covered in this task include  anger, anxiety, craving, empathetic pain, fear, horror, joy, relief, sadness, and surprise.</p>

<p><em>Participants are encouraged to make their code public with their submission.</em></p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>As implied by the popular proverb “a picture is worth a thousand words,” visual contents are an effective means to convey not only facts but also cues about sentiments and emotions. Such cues representing the emotions and sentiments of the photographers may trigger similar feelings from the observer and could be of help in understanding visual contents beyond semantic concepts in different application domains, such as education, entertainment, advertisement, and journalism. To this aim, masters of photography have always utilized smart choices, especially in terms of scenes, perspective, angle of shooting, and color filtering, to let the underlying information smoothly flow to the general public. Similarly, every user aiming to increase in popularity on the Internet will utilize the same tricks. However, it is not fully clear how such emotional cues can be evoked by visual contents and more importantly how the sentiments derived from a scene by an automatic algorithm can be expressed. This opens an interesting line of research to interpret emotions and sentiments perceived by users viewing visual contents.</p>

<h4 id="target-group">Target group</h4>
<p>The task is appropriate for researchers in machine learning, multimedia retrieval, sentiment analysis, and visual analysis.</p>

<h4 id="data">Data</h4>
<p>We provide a slightly modified version of our visual sentiment analysis dataset [1], including a different training and testing set, consisting of disaster-related images collected from social media platforms such as Google, Flickr, and Twitter.</p>

<h4 id="ground-truth">Ground truth</h4>
<p>The dataset was annotated through a crowd-sourcing study using Microworkers, where at least five different participants were assigned to annotate each image. The final tags were chosen based on a majority vote from the five participants assigned to it. The study concluded with 10,010 different responses from 2,338 participants. The participants included individuals from different age groups and 98 countries. The time spent by a participant on an image, which helped filter out careless or inappropriate responses. Before the study, two trial studies were performed to test, correct errors, and improve clarity and readability.
<!-- # This description needs to make clear what the crowdworkers were actually asked. It seems that they are not reporting their own experience of the emotional impact of the photographs, but rather the intention of the photographer--></p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p>All the tasks will be evaluated using standard classification metrics, where weighted F1-Score will be used to rank the different submissions. We also encourage participants to carry out a failure analysis of the results to gain insight into why a classifier may make a mistake.</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->
<p>[1] <a href="https://arxiv.org/pdf/2009.03051.pdf">Hassan, Syed Zohaib, et al. “Visual Sentiment Analysis from Disaster Images in Social Media.” arXiv preprint arXiv:2009.03051 (2020).</a></p>

<p>[2] <a href="https://arxiv.org/abs/1910.04416">Hassan, Syed Zohaib, et al. “Sentiment analysis from images of natural disasters.” International Conference on Image Analysis and Processing. Springer, Cham, 2019.</a></p>

<p>[3] <a href="https://arxiv.org/pdf/2004.11639.pdf">Ortis, Alessandro, Giovanni Maria Farinella, and Sebastiano Battiato. “Survey on visual sentiment analysis.” IET Image Processing 14.8 (2020): 1440-1456.</a></p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Kashif Ahmad, kahmad (at) hbku.edu.qa, Hamad Bin Khalifa University, Doha, Qatar</li>
  <li>Michael Riegler, michael (at) simula.no, SimulaMet, Norway</li>
  <li>Zohaib Hassan, syed (at) simula.no, SimulaMet and OsloMet, Norway</li>
  <li>Steven Hicks, steven (at) simula.no, SimulaMet and OsloMet, Norway</li>
  <li>Nicola Conci, nicola.conci (at) unitn.it, University of Trento, Italy</li>
  <li>Pål Halvorsen, paalh (at) simula.no, SimulaMet and OsloMet, Norway</li>
  <li>Ala Al-Fuqaha, aalfuqaha (at) hbku.edu.qa, Hamad Bin Khalifa University, Doha, Qatar</li>
</ul>

<h4 id="task-schedule-updated">Task Schedule (Updated)</h4>
<ul>
  <li>August : Data release <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>15 November: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>20 November: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>29 November: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>13-15 December: MediaEval 2021 Workshop <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
