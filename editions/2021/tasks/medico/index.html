<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Medico: Transparency in Medical Image Segmentation | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Medico: Transparency in Medical Image Segmentation" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/medico/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/medico/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2026-01-16T14:25:49+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Medico: Transparency in Medical Image Segmentation" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2026-01-16T14:25:49+00:00","datePublished":"2026-01-16T14:25:49+00:00","description":"See the MediaEval 2021 webpage for information on how to register and participate.","headline":"Medico: Transparency in Medical Image Segmentation","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/medico/"},"url":"https://multimediaeval.github.io/editions/2021/tasks/medico/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2026/" style="color:white;">MediaEval 2026</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2025/">MediaEval 2025</a></li>
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2026/" style="color:white;">MediaEval 2026</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2025/">MediaEval 2025</a></li>
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Medico: Transparency in Medical Image Segmentation</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>The fight against colorectal cancer requires better diagnosis tools. Computer-aided diagnosis systems can reduce the chance that diagnosticians overlook a polyp during a colonoscopy. As machine learning becomes more common, even in high-risk fields like medicine, the need for transparent systems becomes more critical. In this case, transparency is defined as giving as much detail as possible on the different parts that make up a machine learning pipeline, including everything from data collection to final prediction. This task focuses on robust, transparent, and efficient algorithms for polyp segmentation.</p>

<p>The data consists of a large number of endoscopic images of the colon, which have been labeled by expert gastroenterologists.</p>

<p><em>Subtask 1: Polyp Segmentation:</em> The polyp segmentation task asks participants to develop algorithms for segmenting polyps in images taken from endoscopies. The main focus of this task is to achieve high segmentation metrics on the supplied test dataset. Since <a href="https://multimediaeval.github.io/editions/2020/tasks/medico/">Medico 2020</a>, we have extended the development dataset and created a new testing dataset to which the submissions will be evaluated on.</p>

<p><em>Subtask 2: Algorithm Efficiency</em> The algorithm efficiency task is similar to subtask one, but puts a stronger emphasis on the algorithm’s speed in terms of frames-per-second. To ensure a fair evaluation, this task requires participants to submit a Docker image so that all algorithms are evaluated on the same hardware.</p>

<!-- # People might get confused on the difference between transparency, explainability, and interpretibility when it comes to machine learning. Could this be made clearer?-->
<p><em>Subtask 3: Transparent Machine Learning Systems</em> The transparency task tries to measure the transparency of the systems used for the aforementioned segmentation tasks. The main focus for this task is to evaluate systems from a transparency point of view, meaning for example explanations of how the model was trained, the data that was used, and interpretation of a model’s predictions.</p>

<p>Participants are encouraged to make their code public with their submission.</p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>Medical image segmentation is a topic that has garnered a lot of attention over the last few years. Compared to classification and object detection, segmentation gives a more precise region of interest for a given class. This is immensely useful for the doctors as it not only specifies that an image contains something interesting but also where to look at which also provides some kind of inherent explanation. Colonoscopies are a perfect use-case for medical image segmentation as they contain a great variety of different findings that may be easily overlooked during the procedure. Furthermore, transparent and interpretable machine learning systems are important to explain the <em>whys</em> and the <em>hows</em> of the predictions. This is especially important in medicine, where conclusions based on wrong decisions resulted from either biased or incorrect data, faulty evaluation or simply a bad model could be fatal. For this reason, the <em>Medico: Transparency in Medical Image Segmentation</em> task aims to develop automatic segmentation systems that are transparent and explainable.</p>

<h4 id="target-group">Target group</h4>
<p>The task is of interest to the researchers working with multimedia segmentation, deep learning (semantic segmentation), and computer vision. We especially encourage young researchers to contribute to the field of endoscopy by developing an automated computer-aided diagnosis system that could be potentially used in clinical settings.</p>

<h4 id="data">Data</h4>
<p><em>Subtask 1: Polyp Segmentation:</em> We will use a slightly modified version of the segmentation part of HyperKvasir [1] that will include additional polyps for training and a separate testing dataset.</p>

<p><em>Subtask 2: Algorithm Efficiency</em> Same as subtask 1.</p>

<p><em>Subtask 3: Transparent Machine Learning Systems</em> The transparent machine learning system task will be based on the previous two tasks and will use each respective dataset.</p>

<h4 id="ground-truth">Ground truth</h4>
<p>The ground truth for the provided dataset was created by an experienced computer scientist and medical doctor, which was then verified by an expert gastroenterologist with over ten years of experience.</p>

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p><em>Subtask 1: Polyp Segmentation</em> We will use the standard metrics commonly used to evaluate segmentation tasks, similar to what was presented in <a href="https://multimediaeval.github.io/editions/2020/tasks/medico/">Medico 2020</a>. This includes the Dice coefficient, pixel accuracy, and the Intersection-Over-Union (Jaccard index). The metric which will be used to rank submissions will be the Intersection-Over-Union coefficient.</p>

<p><em>Subtask 2: Algorithm Efficiency</em> For the Algorithm Efficiency Task, we require participants to submit their detection algorithm as part of a Docker image so that we can evaluate it on our hardware. Submissions for this task will be evaluated based on the algorithms speed and segmentation performance. Speed will be measured by frames-per-second, while segmentation performance will be measured using the same metrics as described in Task 1.</p>

<p><em>Subtask 3: Transparent Machine Learning Systems:</em> We perform a qualitative evaluation of the submission. Here, a multi-disciplinary team will evaluate the submissions based on how transparent and understandable they are. We encourage participants to perform failure analysis on their results, which will contribute to more insight into where a model makes mistakes, contributing to the overall transparency of the system.</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # Please add the links! The paper title should be a hyperlink leading to the paper online-->
<!-- # Adding more literature on explainability would be helpful-->
<p>[1] <a href="https://www.nature.com/articles/s41597-020-00622-y">Borgli, H., Thambawita, V., Smedsrud, P.H. et al. HyperKvasir, a comprehensive multi-class image and video dataset for gastrointestinal endoscopy. Sci Data 7, 283 (2020).</a></p>

<p>[2] <a href="https://link.springer.com/chapter/10.1007/978-3-319-24574-4_28">Ronneberger O, Fischer P, Brox T. U-net: Convolutional networks for biomedical image segmentation. In Proceeding of International Conference on Medical image computing and computer-assisted intervention (MICCAI), 234-241, 2015.</a></p>

<p>[3] <a href="https://doi.org/10.1007/978-3-030-28954-6_2">Weller, A. (2019). Transparency: Motivations and Challenges. In W. Samek, G. Montavon, A. Vedaldi, L. K. Hansen, &amp; K.-R. Müller (Eds.), Explainable AI: Interpreting, Explaining and Visualizing Deep Learning (pp. 23–40). Springer International Publishing.</a></p>

<p>[4] <a href="https://link.springer.com/book/10.1007/978-3-030-28954-6">Explainable AI: Interpreting, Explaining and Visualizing Deep Learning 2019 (pp. 23-40). Springer, Cham.</a></p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Steven Hicks, SimulaMet, Norway steven (at) simula.no</li>
  <li>Debesh Jha, SimulaMet, Norway  debesh (at) simula.no</li>
  <li>Vajira Thambawita, SimulaMet and OsloMet, Norway</li>
  <li>Hugo Hammer, OsloMet, Norway</li>
  <li>Thomas de Lange, Bærum Hospital, Norway</li>
  <li>Sravanthi Parasa, Swedish Medical Center, Sweden</li>
  <li>Michael Riegler, SimulaMet, Norway</li>
  <li>Pål Halvorsen, SimulaMet and OsloMet, Norway</li>
</ul>

<h4 id="task-schedule-updated">Task Schedule (Updated)</h4>
<ul>
  <li>1 July: Data release <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>16 November: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>22 November: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>29 November: Working notes paper  <!-- Fixed. Please do not change. Exact date to be decided--></li>
  <li>13-15 December 2021: MediaEval 2021 Workshop Online <!-- Fixed. Please do not change. Exact date to be decided--></li>
</ul>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
