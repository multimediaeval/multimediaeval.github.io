<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>NewsImages | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="NewsImages" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2021 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2021/tasks/newsimages/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2021/tasks/newsimages/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-01-31T08:04:38+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="NewsImages" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-01-31T08:04:38+00:00","datePublished":"2024-01-31T08:04:38+00:00","description":"See the MediaEval 2021 webpage for information on how to register and participate.","headline":"NewsImages","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2021/tasks/newsimages/"},"url":"https://multimediaeval.github.io/editions/2021/tasks/newsimages/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2023/" style="color:white;">MediaEval 2023</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2023/" style="color:white;">MediaEval 2023</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>NewsImages</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2021/">MediaEval 2021 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>News articles use both text and images to communicate their message. The overall goal of this task is to better understand the relationship between the textual and visual (images) content of news articles, and the impact of these elements on readers’ interest in the news.</p>

<p>Within this task participants are expected to discover and develop patterns/models to describe the relation between:</p>
<ul>
  <li>The images and the text of news articles (including text body, and headlines), and</li>
  <li>The news items and the users’ interest in them (measured by the number of views).</li>
</ul>

<!-- # The following was adapted to make it consistent with the info in Data below-->
<p>To do this, the participants will be provided a sizable real-world dataset of news items, each consisting of textual features (headline and snippet) as well the link to download the accompanying image.</p>

<p>The task requires extracting features from visual images and textual descriptions. Participants must analyze the features’ correlation concerning the context, noise, and the topic domain.</p>

<p>The NewsImages task includes two subtasks: Image-Text Re-Matching and News Click Prediction. The participants can choose to participate in either or both subtasks.</p>

<p><em>Participants are encouraged to make their code public with their submission.</em> 
<!-- # The following sentence is strange. All tasks are headed for the proceedings. I would leave it out and then later announce the special issue if/when relevant
There will also be publishing opportunities at the end of the task.--></p>

<p><strong><em>Subtask 1: Image-Text Re-Matching:</em></strong> News articles often contain images that accompany the text. The connection between the images and the text is more complex than often realized. Aspects such as readers’ attention, difference between authentic imagery and stock photos, and placement on the website play important roles. We encourage participants to consider the explainability of their models. In this subtask, by using the news articles and accompanying images in the provided dataset, participants should predict which image was published with a given news article. We also ask participants to report their insights into characteristics that connect the text of news articles and the images. We expect that these insights contribute to the understanding of the image-text relationship in news articles.</p>

<p><strong><em>Subtask 2: News Click Prediction:</em></strong> News websites present recommendations to users suggesting what to read next. These are often displayed as the article title accompanied by an image. In this task, participants investigate whether recommendations that are frequently clicked by users can be predicted using the textual content of the article and/or the accompanying image. Publishers tend to focus on click-related scores to determine the value of recommendations.</p>

<h4 id="motivation-and-background">Motivation and background</h4>
<p>Online news articles are multimodal: the textual content of an article is often accompanied by an image. The image is important for illustrating the content of the text, but also attracting readers’ attention. Research in multimedia and recommender systems generally assumes a simple relationship between images and text occurring together. For example, in image captioning [6], the caption is often assumed to describe the literally depicted content of the image. In contrast, when images accompany news articles, the relationship becomes less clear [8]. The goal of this task is to investigate these intricacies in more depth, in order to understand the implications that it may have for the areas of journalism and recommender systems.</p>

<p>The task is formulated into two straightforward subtasks that participants can address using text-based and/or image features. However, the ultimate objective of this task is to gain additional insight. Specifically, we are curious about the connection between the textual content of articles and the images that accompany them and also about the connection between the image and title shown by a recommender system to users and the tendency of users to click on the recommended article. We are especially interested in aspects of images that go beyond the conventional set of concepts studied by concept detection. We are also interested in aspects of images that go beyond the literally depicted content. Such aspects include color, style, and framing.</p>

<h4 id="target-group">Target group</h4>
<p>This task targets researchers who are interested in the connection between images and text and images and user behavior. This includes people working in the areas of computer vision, recommender systems, cross-modal information retrieval, as well as in the area of news analysis.</p>

<h4 id="data">Data</h4>
<p>The data set is a large collection of news articles from a German publisher that publishes news article recommendations on its website. Each article consists of a headline and a text snippet (first 256 characters) plus the link to download the accompanying image. The data is split into a training set (ground truth provided) and a test set. Participants must crawl the images themselves as we lack the necessary copyright to provide them directly. To strictly ensure fair comparison, the final test set will include the test set articles for which all participants could successfully access the images.</p>

<ul>
  <li>Training: 15,000 (2 ¼ h to download)</li>
  <li>Test: 5,000 (45min to download)</li>
  <li>After the crawl stage, participants all send the list of images that they cannot access, and everyone throws these images out of their dataset, so that the official dataset for the year contains only images that all participants can access. A deadline for this process will be announced later on.</li>
</ul>

<!-- # If you are planning to release image features, that information should be added here.-->

<h4 id="evaluation-methodology">Evaluation methodology</h4>
<p><strong><em>Subtask 1: Image-Text Re-Matching:</em></strong> For each news article in the test set, participants return the top five images that they predict to have accompanied that article. The ground truth (the correct news article-image-connection) is defined by the image that was published in the news article on the web portal. 
We encourage participants to additionally provide confidence scores such that we can learn more about the robustness of their methods. Success is measured with Precision@5. This means, that for each news item, 5 images should be suggested. If the correct images is in the suggested set, the predction is seen as correct. Since only one image per news item is correct, the metric could also be seen as Recall@5.
Additionally, we promote the idea of explainability and ask the participants to look into the inner workings of their methods. What does the model tell? For which instances has the method failed and why?</p>

<!-- # Please add a sentence to explicitly explain the ground truth. AL: I added one sentence explaining this issue. -->

<p><strong><em>Subtask 2: News Click Prediction:</em></strong> Given a set of images, participants predict the topmost news articles that are likely to be clicked when they are recommended. The number of top images will be specified. Success is measured by precision. More concretely, participants score each image which induces a ranking. We will determine the precision at a suited cut off point. Again, we encourage participants to examine their models and try to explain what they have picked up.</p>

<p><em>Analysis and Insight:</em> For both tasks, the ultimate goal is to understand news and news consumption behavior. We will also judge participants in terms of the quality of the insight that they achieve about the relationship between text and images and in the relationship between images and news consumption behavior.</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->
<p>[1] Corsini, Francesco, and Martha A. Larson. <a href="https://repository.ubn.ru.nl/bitstream/handle/2066/161886/161886.pdf">CLEF NewsREEL 2016: image based recommendation.</a> (2016).</p>

<p>[2] Das, A. S., Datar, M., Garg, A., &amp; Rajaram, S. (2007, May). <a href="https://dl.acm.org/doi/abs/10.1145/1242572.1242610">Google news personalization: scalable online collaborative filtering</a>. In Proceedings of the 16th international conference on World Wide Web (pp. 271-280).</p>

<p>[3] Garcin, F., Faltings, B., Donatsch, O., Alazzawi, A., Bruttin, C., &amp; Huber, A. (2014, October). <a href="https://dl.acm.org/doi/abs/10.1145/2645710.2645745">Offline and online evaluation of news recommender systems at swissinfo.ch</a>. In Proceedings of the 8th ACM Conference on Recommender systems (pp. 169-176).</p>

<p>[4] Ge, M., &amp; Persia, F. (2017). <a href="https://www.worldscientific.com/doi/abs/10.1142/S1793351X17500039">A survey of multimedia recommender systems: Challenges and opportunities.</a> International Journal of Semantic Computing, 11(03), 411-428.</p>

<p>[5] Hopfgartner, F., Balog, K., Lommatzsch, A., Kelly, L., Kille, B., Schuth, A., &amp; Larson, M. (2019). <a href="https://link.springer.com/chapter/10.1007/978-3-030-22948-1_21">Continuous evaluation of large-scale information access systems: a case for living labs.</a> In Information Retrieval Evaluation in a Changing World (pp. 511-543). Springer, Cham.</p>

<p>[6] Hossain, M. Z., Sohel, F., Shiratuddin, M. F., &amp; Laga, H. (2019). <a href="https://dl.acm.org/doi/abs/10.1145/3295748">A comprehensive survey of deep learning for image captioning.</a> ACM Computing Surveys (CSUR), 51(6), 1-36.</p>

<p>[7] Lommatzsch, A., Kille, B., Hopfgartner, F., Larson, M., Brodt, T., Seiler, J., &amp; Özgöbek, Ö. (2017, September). <a href="https://link.springer.com/book/10.1007/978-3-319-65813-1">CLEF 2017 NewsREEL overview: A stream-based recommender task for evaluation and education.</a> In International Conference of the Cross-Language Evaluation Forum for European Languages (pp. 239-254). Springer, Cham.</p>

<p>[8] Oostdijk, N., van Halteren, H., Bașar, E., &amp; Larson, M. (2020, May). <a href="https://www.aclweb.org/anthology/2020.lrec-1.535/">The Connection between the Text and Images of News Articles: New Insights for Multimedia Analysis.</a> In Proceedings of The 12th Language Resources and Evaluation Conference (pp. 4343-4351).</p>

<h4 id="task-organizers">Task organizers</h4>
<ul>
  <li>Andreas Lommatzsch, TU Berlin, Germany</li>
  <li>Benjamin Kille, TU Berlin, Germany</li>
  <li>Özlem Özgöbek, NTNU Trondheim, Norway</li>
  <li>Duc Tien Dang Nguyen, University of Bergen, Norway</li>
  <li>Mehdi Elahi, University of Bergen, Norway</li>
</ul>

<h4 id="task-schedule-updated">Task Schedule (Updated)</h4>
<ul>
  <li>30 June 2021: Data is made available <!-- # Replace XX with your date. We suggest setting the date in June-July--></li>
  <li>07 November 2021: Runs due <!-- # Replace XX with your date. We suggest setting enough time in order to have enough time to assess and return the results by the Results returned deadline--></li>
  <li>15 November 2021: Results returned  <!-- Replace XX with your date. Latest possible should be 15 November--></li>
  <li>29 November 2021: Working notes paper due <!-- Fixed. Please do not change--></li>
  <li>13-15 December 2021: MediaEval 2021 Workshop Online <!-- Fixed. Please do not change--></li>
</ul>

<!-- #### Acknolwedgments-->
<!-- # optional, delete if not used-->


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
