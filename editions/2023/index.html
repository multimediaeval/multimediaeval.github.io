<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>MediaEval 2023 | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="MediaEval 2023" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data. Participants address these challenges by creating algorithms for retrieval, analysis, and exploration. Solutions are systematically compared using a common evaluation procedure, making it possible to establish the state of the art and track progress. Our larger aim is to promote reproducible research that makes multimedia a positive force for society." />
<meta property="og:description" content="The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data. Participants address these challenges by creating algorithms for retrieval, analysis, and exploration. Solutions are systematically compared using a common evaluation procedure, making it possible to establish the state of the art and track progress. Our larger aim is to promote reproducible research that makes multimedia a positive force for society." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2023/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2023/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2025-06-24T20:09:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="MediaEval 2023" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2025-06-24T20:09:00+00:00","datePublished":"2025-06-24T20:09:00+00:00","description":"The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data. Participants address these challenges by creating algorithms for retrieval, analysis, and exploration. Solutions are systematically compared using a common evaluation procedure, making it possible to establish the state of the art and track progress. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.","headline":"MediaEval 2023","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2023/"},"url":"https://multimediaeval.github.io/editions/2023/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>MediaEval 2023</h2>
  </header>

  <p>The MediaEval Multimedia Evaluation benchmark offers challenges in artificial intelligence for multimedia data. Participants address these challenges by creating algorithms for retrieval, analysis, and exploration. Solutions are systematically compared using a common evaluation procedure, making it possible to establish the state of the art and track progress. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.</p>

<p>MediaEval goes beyond other benchmarks and data science challenges in that it also pursues a “Quest for Insight” (Q4I). With Q4I we push beyond only striving to improve evaluation scores to also working to achieve deeper understanding about the challenges. For example, properties of the data,  strengths and weaknesses of particular types of approaches, and observations about the evaluation procedure.</p>

<p>The MediaEval 2023 Workshop will be held 1-2 February, collocated with <a href="https://mmm2024.org">MMM 2024</a> in Amsterdam, Netherlands and also online.</p>

<h3 id="workshop">Workshop</h3>

<!-- * Register for the workshop here: [MediaEval 2021 Workshop Registration Form](https://multimediaeval.github.io/editions/2021/docs/MediaEval2021WorkshopScheduleAndThanks.pdf) -->
<ul>
  <li>Workshop schedule is here: <a href="https://multimediaeval.github.io/editions/2023/docs/MultimediaEval_2023_Detailed_Program.pdf">MediaEval 2023 Workshop Program</a></li>
  <li>Proceedings: <a href="https://ceur-ws.org/Vol-3658/">MediaEval 2023 Working Notes Proceedings</a></li>
</ul>

<p>Workshop group photo:</p>

<p><img src="https://multimediaeval.github.io/editions/2023/docs/mediaeval2023GroupPhoto.jpg" width="300" /></p>

<h3 id="task-schedule">Task schedule</h3>
<ul>
  <li>July-September 2023: Validation data release</li>
  <li>October 2023: Test data release</li>
  <li>15-30 November: Runs due (see the individual tasks pages below for the exact deadlines)</li>
  <li>15 December 2023: Working notes papers due</li>
  <li>1-2 February 2024: MediaEval 2023 Workshop, Collocated with <a href="https://mmm2024.org">MMM 2024</a> in Amsterdam, Netherlands and Online.</li>
</ul>

<h5 id="the-mediaeval-coordination-committee-2023">The MediaEval Coordination Committee (2023)</h5>
<ul>
  <li>Mihai Gabriel Constantin, University Politehnica of Bucharest, Romania</li>
  <li>Steven Hicks, SimulaMet, Norway</li>
  <li>Martha Larson, Radboud University, Netherlands (Overall coordinator and main contact person)</li>
</ul>

<p>MediaEval is grateful for the support of <a href="http://sigmm.org/">ACM Special Interest Group on Multimedia</a></p>

<p><img src="https://multimediaeval.github.io/editions/2020/docs/sigmmlogo.gif" width="150" /></p>

  
  

  
  <h3>
    Task List
  </h3>

  
  <ul class="right hide-on-med-and-down"></ul>
  
    <a href="https://multimediaeval.github.io/editions/2023/tasks/medico/"><h4>Medical Multimedia Task - Transparent Tracking of Spermatozoa</h4></a>
    <p>Participants detect and track sperm in microscope videos, using provided microscope videos and metadata. They must analyze both global and individual sperm attributes such as motility, speed, and distance traveled. The annotations follow WHO sperm quality standards and are verified by experts.</p>
    <a href="https://multimediaeval.github.io/editions/2023/tasks/medico/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2023/tasks/musti/"><h4>Musti: Multimodal Understanding of Smells in Texts and Images</h4></a>
    <p>Participants develop classifiers to predict whether a text passage and an image evoke the same smell source or not and identify common smell sources text passages and images. Optionally, the challenge can be addressed in a cross-language setting.</p>
    <a href="https://multimediaeval.github.io/editions/2023/tasks/musti/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2023/tasks/newsimages/"><h4>NewsImages: Connecting Text and Images</h4></a>
    <p>Participants are supplied with a large set of articles (including text body, and headlines) and the accompanying images from international publishers. The task requires participants to predict which image was used to accompany each article.</p>
    <a href="https://multimediaeval.github.io/editions/2023/tasks/newsimages/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2023/tasks/memorability/"><h4>Predicting Video Memorability</h4></a>
    <p>Participants automatically predict memorability scores for videos that reflect the probability that a video will be remembered. They will be provided with an extensive data set of videos with memorability annotations, related information, pre-extracted state-of-the-art visual features, and Electroencephalography (EEG) recordings.</p>
    <a href="https://multimediaeval.github.io/editions/2023/tasks/memorability/">Read more.</a>
    <br>
  
    <a href="https://multimediaeval.github.io/editions/2023/tasks/sportsvideo/"><h4>SportsVideo: Fine Grained Action Classification and Position Detection in Table Tennis and Swimming Videos</h4></a>
    <p>Participants address video analysis challenges in two sports: table tennis and swimming videos. Subtasks include position detection and action classification and involve leveraging different modalities in the video data: visual, sound, and text.</p>
    <a href="https://multimediaeval.github.io/editions/2023/tasks/sportsvideo/">Read more.</a>
    <br>
  
</ul>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
