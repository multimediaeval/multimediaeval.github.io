<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Insight for Wellbeing: Multimodal personal health lifelog data analysis | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Insight for Wellbeing: Multimodal personal health lifelog data analysis" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="See the MediaEval 2020 webpage for information on how to register and participate." />
<meta property="og:description" content="See the MediaEval 2020 webpage for information on how to register and participate." />
<link rel="canonical" href="https://multimediaeval.github.io/editions/2020/tasks/lifelogging/" />
<meta property="og:url" content="https://multimediaeval.github.io/editions/2020/tasks/lifelogging/" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2024-09-24T13:33:15+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Insight for Wellbeing: Multimodal personal health lifelog data analysis" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2024-09-24T13:33:15+00:00","datePublished":"2024-09-24T13:33:15+00:00","description":"See the MediaEval 2020 webpage for information on how to register and participate.","headline":"Insight for Wellbeing: Multimodal personal health lifelog data analysis","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/editions/2020/tasks/lifelogging/"},"url":"https://multimediaeval.github.io/editions/2020/tasks/lifelogging/"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2025/" style="color:white;">MediaEval 2025</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2023/">MediaEval 2023</a></li>
  
  <li><a href="/editions/2022/">MediaEval 2022</a></li>
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
          <header id="main" style="background-image: url('')">
    <h2>Insight for Wellbeing: Multimodal personal health lifelog data analysis</h2>
  </header>

  <!-- # please respect the structure below-->
<p><em>See the <a href="https://multimediaeval.github.io/editions/2020/">MediaEval 2020 webpage</a> for information on how to register and participate.</em></p>

<h4 id="task-description">Task Description</h4>
<p>Task participants create systems that derive insights from multimodal lifelog data that are important for health and wellbeing. The first dataset, namely “personal air quality data” (PAQD), includes air pollution data (PM2.5, O3, and NO2) and lifelog data (e.g., physiological data, tags, and images) collected by using sensors boxes, lifelog cameras, and smartphones along the predefined routes in a city. The second dataset, namely “global air quality data” (GAQD), includes weather and air pollution data collected over the city and provided by the government and crawled from related websites.</p>

<p>Participants in this task tackle two challenging subtasks:</p>
<ol>
  <li>Personal Air Quality Prediction with public/open data: Task participants predict the value of personal air pollution data (PM2.5, O3, and NO2) using only weather data (wind speed, wind direction, temperature, humidity) and air pollution data (PM2.5, O3, and NO2) from public/open data sources (e.g., stations, website).  This subtask’s target is to investigate whether we can use public/open data to predict personal air pollution data. The personal air pollution data can be concerned as the regional air pollution data since these data a locally collected by people who carry personal equipment. In other words, the ground truth is data collected by sensor boxes carried by people.</li>
  <li>Personal Air Quality Prediction with lifelog data: participants predict the personal Air Quality Index using images captured by people (plus GAQD). The purpose of this subtask is whether we can use only lifelog data (i.e., pictures of the surrounding environment, annotations, and comments), plus some data from open sources (e.g., weather, air pollution data) to predict the personal air pollution data.</li>
</ol>

<h4 id="motivation-and-background">Motivation and Background</h4>
<p>The association between people’s wellbeing and the properties of the surrounding environment is an essential area of investigation. Although these investigations have a long and rich history, they have focused on the general population. There is a surprising lack of research investigating the impact of the environment on the scale of individual people. On a personal scale, local information about air pollution (e.g., PM2.5, NO2, O3), weather (e.g., temperature, humidity), urban nature (e.g., greenness, liveliness, quietness), and personal behavior (e.g., psychophysiological data) play an essential role. It is not always possible to gather plentiful amounts of such data. As a result, a key research question remains open: Can sparse or incomplete data be used to gain insight into wellbeing? Is there a hypothesis about the associations within the data so that wellbeing can be understood using a limited amount of data? Developing hypotheses about the associations within the heterogeneous data contributes towards building good multimodal models that make it possible to understand the impact of the environment on wellbeing at the local and individual scale. Such models are necessary since not all cities are fully covered by standard air pollution and weather stations, and not all people experience the same reaction to the same environment situation. Moreover, images captured by the first-person view could give essential cues to understand that environmental situations in cases in which precise data from air pollution stations are lacking.</p>

<p>Let us imagine the following scenario. Yamamoto-san is using the Image-2-AQI app to know how harmful air pollution is by merely feeding captured images to the app. Simultaneously, at the urban air pollution center, the air pollution map is updated with Yamamoto-san’s contribution (e.g., images, annotation). Satoh-san, with some clicks on his smartphone, the environmental-based risk map application can show him the excellent route from A to B with less congestion and harmful air pollution. Simultaneously, less congestion from A to B is due to fewer people coincidentally traveling on the same route. Such simple apps are parts of the human-environment sustainable and co-existing system that have changed people’s pro-environmental behaviors.</p>

<p>The critical research question here is, “does the personal air quality be predicted by using other data that is easy to obtain?”</p>

<h4 id="target-group">Target Group</h4>
<p>This task targets (but is not limited to) researchers in the areas of multimedia information retrieval, machine learning, AI, data science, event-based processing and analysis, multimodal multimedia content analysis, lifelog data analysis, urban computing, environmental science, and atmospheric science.</p>

<h4 id="data">Data</h4>
<p>The personal air quality data (PAQD) were collected from March to April 2019 along the marathon course of the Tokyo 2020 Olympics and the running course around the Imperial Palace using wearable sensors. There were five data collection participants assigned to five routes to collect the data. Routes 1–4 were along the marathon course for the Tokyo 2020 Olympics. Route 5 was the running course around the Imperial Palace. The length of each route was approximately 5 km. Each participant started data collection at 9 am every weekday, and it took approximately one hour to walk each route.  Collected data contain weather data (e.g., temperature, humidity), atmospheric data (e.g., O3, PM2.5, and NO2), GPS data, and lifelog data (e.g., images, annotation).</p>

<p>The glocal air pollution data (GAPD) contains the atmospheric monitoring station data collected by the Atmospheric Environmental Regional Observation System (AEROS) in Japan (http://soramame.taiki.go.jp). AEROS contains real-time atmospheric data at every hour for 2032 meteorological monitoring stations across Japan. The atmospheric data includes eleven types of air pollutant data (SO2, NOx, NO, NO2, CO, Ox, NMHC, CH4, THC, SPM, and PM2.5), and four types of meteorological data (wind direction, wind speed, temperature, and humidity).</p>

<p>All data are stored in CSV format, except images in JPG format. Personal data are privacy protected. All task participants should sign the agreement of using these data, released by MediaEval and NICT-Japan, for research purposes only.</p>

<h4 id="evaluation-methodology">Evaluation Methodology</h4>
<p>The ground truth for the dataset of the two subtasks is collected as follows:</p>
<ul>
  <li>For the Personal Air Quality Prediction with public/open data subtask: some parts of personal (PM2.5, O3, and NO2) data are deleted and saved as the ground truth.</li>
  <li>For the Personal Air Quality Prediction with lifelog data subtask: the set of personal AQI are hidden and saved as the ground truth</li>
</ul>

<p>For each subtask, the evaluation method is applied as follows:</p>
<ul>
  <li>For the Personal Air Quality Prediction with public/open data subtask: We use the SMAPE/RMSE/MAE for comparing each air pollution factor PM2.5, O3, and NO2 with the ground truth.</li>
  <li>For the Personal Air Quality Prediction with lifelog data subtask: We use the SMAPE/RMSE/MAE for comparing predicted AQI to the ground truth.</li>
</ul>

<p>The formulation for computing AQI value from (PM2.5, O3, and NO2) data can be found at</p>

<p>https://en.wikipedia.org/wiki/Air_quality_index (prefer the “Computing the AQI” section)</p>

<p>https://airtw.epa.gov.tw/ENG/Information/Standard/AirQualityIndicator.aspx (prefer the “real-time table” that is the look-up table for C_low, C_high, I_low, I_high value)</p>

<h4 id="references-and-recommended-reading">References and recommended reading</h4>
<!-- # Please use the ACM format for references https://www.acm.org/publications/authors/reference-formatting (but no DOI needed)-->
<!-- # The paper title should be a hyperlink leading to the paper online-->
<p>[1] Sato, T., Dao, M.S., Kuribayashi, K., and Zettsu, K.: <a href="https://link.springer.com/chapter/10.1007/978-3-030-05710-7_27">SEPHLA: Challenges and Opportunities within Environment – Personal Health Archives</a>, MMM 2018.</p>

<p>[2] P. Zhao and K. Zettsu, <a href="https://ieeexplore.ieee.org/document/9006604">Decoder Transfer Learning for Predicting Personal Exposure to Air Pollution</a>, 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 5620-5629.</p>

<p>[3] N. Nguyen, M. Dao and K. Zettsu, <a href="https://ieeexplore.ieee.org/abstract/document/9005985">Complex Event Analysis for Traffic Risk Prediction based on 3D-CNN with Multi-sources Urban Sensing Data</a>, 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 1669-1674.</p>

<p>[4] P. Vo, T. Phan, M. Dao and K. Zettsu, <a href="https://ieeexplore.ieee.org/document/90056360">Association Model between Visual Feature and AQI Rank Using Lifelog Data</a>, 2019 IEEE International Conference on Big Data (Big Data), Los Angeles, CA, USA, 2019, pp. 4197-4200.</p>

<p>[5] Dao, M. S., Zhao, P., Sato, T., Zettsu, K., Dang-Nguyen D. T., Gurrin, C., Nguyen, N. T.: Overview of MediaEval 2019: Insights for Wellbeing TaskMultimodal Personal Health Lifelog Data Analysis, MediaEval Benchmarking Initiative for Multimedia Evaluation (MediaEval 2019), Antipolis, France (November 2019).</p>

<p>[6] Song, H., Lane, K. J., Kim, H., Kim, H., Byun, G., Le, M., Choi, Y., Park, C. R., &amp; Lee, J. T. (2019). <a href="https://pubmed.ncbi.nlm.nih.gov/30634488/">Association between Urban Greenness and Depressive Symptoms: Evaluation of Greenness Using Various Indicators</a>, International journal of environmental research and public health, 16(2), 173.</p>

<p>[7] Darshan Santani, Salvador Ruiz-Correa, and Daniel Gatica-Perez. 2018. <a href="https://dl.acm.org/doi/10.1145/3224182">Looking South: Learning Urban Perception in Developing Cities</a>, Trans. Soc. Comput. 1, 3, Article 13 (December 2018), 23 pages.</p>

<p>[8] Anh-Vu Mai-Nguyen, Trong-Dat Phan, Anh-Khoa Vo, Van-Luon Tran, Minh-Son Dao, and Koji Zettsu. 2020. <a href="https://dl.acm.org/doi/10.1145/3379172.3391722">BIDAL-HCMUS@LSC2020: An Interactive Multimodal Lifelog Retrieval with Query-to-Sample Attention-based Search Engine</a>, In Proceedings of the Third Annual Workshop on Lifelog Search Challenge (LSC ’20). Association for Computing Machinery, New York, NY, USA, 43–49.</p>

<p>[9] Tan-Loc Nguyen-Tai, Dang-Hieu Nguyen, Minh-Tam Nguyen, Thanh-Duong Nguyen, Thanh-Hai Dang, and Minh-Son Dao. 2020. <a href="https://dl.acm.org/doi/10.1145/3379174.3392320">MNR-HCM Data: A Personal Lifelog and Surrounding Environment Dataset in Ho-Chi-Minh City, Viet Nam</a>, In Proceedings of the 2020 Intelligent Cross-Data Analysis and Retrieval Workshop (ICDAR ’20). Association for Computing Machinery, New York, NY, USA, 21–26.</p>

<p>[10] Vahdatpour, M., Sajedi, H. &amp; Ramezani, F. <a href="https://link.springer.com/article/10.1007/s12145-018-0334-x">Air pollution forecasting from sky images with shallow and deep classifiers</a>, Earth Sci Inform 11, 413–422 (2018).</p>

<h4 id="task-organizers">Task Organizers,</h4>
<p>Minh-Son Dao (NICT, Japan) dao (at) nict.go.jp</p>

<p>Peijiang Zhao (NICT, Japan) dlzpj (at) nict.go.jp</p>

<p>Ngoc-Thanh Nguyen (UIT, Vietnam) thanhnn.13 (at) grad.uit.edu.vn</p>

<p>Thanh-Binh Nguyen (HCMUS, Vietnam) ngtbinh (at) hcmus.edu.vn</p>

<p>Duc-Tien Dang-Nguyen (UiB, Norway) ductien.dangnguyen (at) uib.no</p>

<p>Cathal Gurrin (DCU, Ireland) cgurrin (at) computing.dcu.ie</p>

<h4 id="task-auxiliaries">Task Auxiliaries</h4>
<!-- # if there are people helping with the task, but are not bearing the main responsibility for the task, they are auxiliaries. Please delete this heading if you have no auxiliaries-->
<p>Tan-Loc Nguyen-Tai (UIT, Vietnam)</p>

<p>Dang-Hieu Nguyen (UIT, Vietnam)</p>

<p>Minh-Tam Nguyen (UIT, Vietnam)</p>

<p>Quoc-Dat Duong (HCMUS, Vietnam)</p>

<p>Minh-Quan Le (HCMUS, Vietnam)</p>

<p>Trong-Dat Phan (HCMUS, Vietnam)</p>

<h4 id="task-schedule">Task Schedule</h4>
<ul>
  <li>31 July: Data release <!-- # Replace XX with your date. Latest possible is 31 July--></li>
  <li><del>30 October</del> 16 November: Runs due + Start writing Working notes paper<!-- # Replace XX with your date. Latest possible is 31 October--></li>
  <li><del>15 November</del> 23 November: Results returned  <!-- Fixed. Please do not change--></li>
  <li>30 November: Working notes paper  <!-- Fixed. Please do not change--></li>
  <li>11, 14-15 December: MediaEval 2020 Workshop (Fully virutal) <!-- Fixed. Please do not change--></li>
</ul>

<p>Workshop will be held online.</p>


      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
