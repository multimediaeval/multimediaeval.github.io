<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.8.0 -->
<title>Call for Task Proposals MediaEval 2021 | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.2" />
<meta property="og:title" content="Call for Task Proposals MediaEval 2021" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society" />
<meta property="og:description" content="The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society" />
<link rel="canonical" href="https://multimediaeval.github.io/2021/03/02/call-2021.html" />
<meta property="og:url" content="https://multimediaeval.github.io/2021/03/02/call-2021.html" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-03-02T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image" />
<meta property="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="twitter:title" content="Call for Task Proposals MediaEval 2021" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2021-03-02T00:00:00+00:00","datePublished":"2021-03-02T00:00:00+00:00","description":"The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society","headline":"Call for Task Proposals MediaEval 2021","image":"https://multimediaeval.github.io/assets/img/twitter-card.png","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/2021/03/02/call-2021.html"},"url":"https://multimediaeval.github.io/2021/03/02/call-2021.html"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    




<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
                <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
            
          
        
          
            
                <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
                <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/philosophy/" style="color:white;">MediaEval Philosophy</a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
        <article >
  <header id="main" style="">
    
      <h1 id="Call+for+Task+Proposals+MediaEval+2021" class="title">Call for Task Proposals MediaEval 2021</h1>
      <div class="post-info">
    <p class="meta">
      March 2, 2021
    </p>
</div>

    
  </header>
  <section class="post-content">
  
      <p>The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society</p>

<p>MediaEval is now calling for proposals for tasks to run in the 2021 benchmarking season.</p>

<p><strong>Full proposal deadline: Wednesday 31 March 2021</strong></p>

<p>The proposal should describe the motivation of the task and define the specific problem that task participants are required to solve. It should provide information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated. The proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art in an area related to multimedia indexing, search or other technologies that support users in accessing multimedia content and collections.</p>

<h5 id="indication-of-intent">Indication of Intent</h5>
<p>If you plan to submit a task proposal, we strongly suggest that as soon as possible you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what participants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.</p>

<h5 id="full-task-proposal">Full Task Proposal</h5>
<p>A task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.</p>

<h6 id="part-i-task-description">Part I: Task Description</h6>
<p>This is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:</p>
<ul>
  <li>Task Title: Give your task an informative title.</li>
  <li>Task Description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.</li>
  <li>Motivation and background: Describe the motivating use scenario, i.e., which application(s) motivate the task. State how the task extends the state of the art.</li>
  <li>Target Group: Describe the type of researchers who would be interested in participating in the task.</li>
  <li>Data: Describe the data, including how the data will be collected and licensed.</li>
  <li>Evaluation Methodology: Describe the evaluation methodology, including how the ground truth will be created.</li>
  <li>References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.</li>
  <li>List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.)
For example task descriptions, please see the task pages of the <a href="https://multimediaeval.github.io/editions/2020/">MediaEval 2020 Tasks</a></li>
</ul>

<h6 id="part-ii-big-picture-of-the-task">Part II: Big Picture of the Task</h6>
<p>Please address each of the following points with 2-3 sentences each:</p>
<ul>
  <li>Innovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task.</li>
  <li>Focus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible research that makes multimedia a positive force for society. Please comment on the human or social aspect of your task.</li>
  <li>Risk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will you face in organizing the task and how do you expect to overcome them)?</li>
</ul>

<h6 id="part-iii-task-organization-team">Part III: Task Organization Team</h6>
<p>Write a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out failure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting early-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.</p>

<p>The MediaEval 2021 Workshop will be held in early December 2021. We are planning on a physical workshop in Bergen, Norway with the opportunity for remote participation.</p>

<p>Please submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl and Gareth Jones gareth (dot) jones (at) computing (dot) dcu (dot) ie</p>


    
  </section>

  <!-- Social media shares -->
  <!-- <div class="share-buttons">
    <ul class="share-buttons">
        <div class="meta">Share</div>
                
    </ul>
</div>
 -->

   <!-- Tag list -->
  <!-- 
  


<footer>
  <div class="tag-list"></div>
</footer>
 -->

</article>

<!-- Post navigation -->

  <div id="post-nav">
    
    <div id="previous-post">
        <p>Next post</p>
        <a alt="MediaEval 2021 Registration" href="/2021/06/16/registration-2021.html">
            MediaEval 2021 Registration
        </a>
    </div>
    
    

    <div id="next-post">
        <p>Previous post</p>
        <a alt="Announcing MediaEval 2021" href="/2020/12/15/annoucing-2021.html">
            Announcing MediaEval 2021
        </a>
    </div>
    
</div>



      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
