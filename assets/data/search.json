[
   
      {
        "title"    : "MediaEval 2025 Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2025/05/07/workshop-registration.html",
        "date"     : "May 7, 2025",
        "excerpt"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or\ncontextual) and fo...",
        "content"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or\ncontextual) and focus on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nSignup for MediaEval 2025 is now open via the MediaEval 2025 registration form\n\nData release will start soon and continue over the next months. Runs will be due at the end of September 2025 and the annual MediaEval Workshop will be held on Sat.-Sun. 25-26 October 2025, in Dublin, Ireland and Online, \nbetween CMBI 2025 and ACM Multimedia 2025. Remote participation will be possible for those who cannot travel to take part in the workshop in person.\n\nMediaEval 2025 is offering the following tasks:\n\n\n  Medico: VQA (with multimodal explanations) for gastrointestinal imaging\n  Memorability: Predicting movie and commercial memorability\n  MultiSumm: Multimodal summarization of multiple topically related websites\n  NewsImages: Retrieval and generative AI for news thumbnails\n  Synthetic Images: Advancing detection of generative AI used in real-world online images\n\n\nMore detailed task descriptions are available on the MediaEval 2025 Website.\n"
      } ,
   
      {
        "title"    : "MediaEval 2025 task descriptions are online",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2025/04/01/task-descriptions.html",
        "date"     : "April 1, 2025",
        "excerpt"  : "The descriptions of the tasks that will be offered this year at the Multimedia Evaluation Benchmark (MediaEval 2025) have now been published on the MediaEval 2025 webpage.\n\nMe...",
        "content"  : "The descriptions of the tasks that will be offered this year at the Multimedia Evaluation Benchmark (MediaEval 2025) have now been published on the MediaEval 2025 webpage.\n\nMediaEval offers challenges in AI that involve data of different modalities. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. \nResults will be presented at the MediaEval 2025 Workshop, Sat.-Sun. 25-26 October 2025, Dublin, Ireland and Online. Between CMBI 2025 and ACM Multimedia 2025.\n\nMediaEval is open to anyone who wishes to participate. Please watch here for an announcement to be posted when registration has opened (mid-April).\n"
      } ,
   
      {
        "title"    : "Announcing the MediaEval 2025 tasks",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2025/01/31/task-list.html",
        "date"     : "January 31, 2025",
        "excerpt"  : "We are happy to announce that the following tasks will be offered at this year at the Multimedia Evaluation Benchmark (MediaEval 2025):\n\n\n  Synthetic Images: Advancing detection of generative AI used in real-world online images...",
        "content"  : "We are happy to announce that the following tasks will be offered at this year at the Multimedia Evaluation Benchmark (MediaEval 2025):\n\n\n  Synthetic Images: Advancing detection of generative AI used in real-world online images\n  MultiSumm: Multimodal summarization of multiple topically related websites\n  NewsImages: Retrieval and generative AI for news thumbnails\n  Memorability: Predicting the memorability of movie clips and commercial videos\n  Medico:  Visual Question Answering (VQA) for gastrointestinal imaging\n\n\nShort descriptions of the tasks and information about the schedule is available on the MediaEval 2025 webpage.\n\nMediaEval offers challenges in AI that involve data of different modalities. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. Results will be presented at the \nMediaEval 2025 Workshop, Sat.-Sun. 25-26 October 2025, Dublin, Ireland and Online. Between CMBI 2025 and ACM Multimedia 2025.\n\nMediaEval is open to anyone who wishes to participate. Please watch here for an announcement to be posted when registration has opened.\n"
      } ,
   
      {
        "title"    : "MediaEval 2025 Call for Task Proposals",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2024/09/24/call.html",
        "date"     : "September 24, 2024",
        "excerpt"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate n...",
        "content"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new \nalgorithms and technologies for analyzing, exploring and accessing information in multimedia data. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including \ndata and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2025 \nbenchmarking season.\n\n\n  Call for Task proposals (first deadline): Wed. 11 December\n  Call for Task proposals (final deadline): Wed. 22 January\n\n\nThe proposal should describe the motivation of the task, including a description of the use scenario in which the results of the tasks would be used (e.g., application that serves users). It should provide a definition of the specific problem that task \nparticipants are required to solve. Also, it should include information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated (the metric and description of how the metric is related to the \nuse scenario). We ask you to think carefully about specific research questions that are related to the challenge, and mention these in the proposal. These research questions will guide participants in pursuing the “Quest for Insight”, i.e., going beyond \nthinking only about evaluation scores. Finally, the proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art.\n\nIndication of Intent\n\nIf you plan to submit a task proposal, we strongly suggest that you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what \nparticipants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.\n\nFull Task Proposal\n\nA task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.\n\nPart I: Task Description\n\nThis is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:\n\n\n  Task title: Give your task an informative title.\n  Task description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.\n  Motivation and background: Describe the motivating use scenario, i.e., how would the results of the task be used in an application that serves users. Also, state how the task extends the state of the art.\n  Target group: Describe the type of researchers who would be interested in participating in the task.\n  Data: Describe the data, including how the data will be collected and licensed.\n  Evaluation methodology: Describe the evaluation methodology, including how the ground truth will be created and the evaluation metrics.\n  “Quest for Insight”: List several research questions related to the challenge, which the participants can strive to answer in order to go beyond just looking at evaluation metrics.\n  References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.\n  List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.)\n\n\nPart II: Big Picture of the Task\n\nPlease address each of the following points with 2-3 sentences each:\n\nInnovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task. \nFocus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible \nresearch that makes multimedia a positive force for society. Please comment on the human or social aspect of your task. Risk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will \nyou face in organizing the task and how do you expect to overcome them)?\n\nPart III: Task Organization Team\n\nWrite a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out \nfailure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting \nearly-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.\n\nSubmission\n\nPlease submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl with Steven Hicks steven (at) simula (dot) no and Mihai Gabriel (Gabi) Constantin \nmihai.constantin84 (at) upb (dot) ro on cc.\n\nMediaEval 2025 Schedule\n\n\n  Registration for task participation opens: April 2025\n  Development data release: May 2025\n  Test data release: June 2025\n  Runs due: Wed. 24 Sept 2025\n  Working notes papers due: Wed. 8 Oct 2025\n  MediaEval 2025 Workshop, Sat.-Sun. 25-26 October 2025, Dublin, Ireland and Online.\n\n\nThe MediaEval 2025 workshop will be held during a weekend so that it can occur exactly between ACM Multimedia 2025 and CBMI 2025. The scheduling helps to reduce traveling for those who are traveling. The workshop will be officially co-located with CBMI 2025.\n"
      } ,
   
      {
        "title"    : "MediaEval Workshop Registration and Information",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2024/01/13/workshop-registration.html",
        "date"     : "January 13, 2024",
        "excerpt"  : "The 14th Annual MediaEval Workshop will take place Thursday-Friday 1-2 February 2024 (8:30-17:00) in Amsterdam, Netherlands and online.\n\nRegister for the workshop on the &lt;a href=&quot;https://www.aanmelder.nl/mediaeval2024/registratio...",
        "content"  : "The 14th Annual MediaEval Workshop will take place Thursday-Friday 1-2 February 2024 (8:30-17:00) in Amsterdam, Netherlands and online.\n\nRegister for the workshop on the MediaEval Workshop registration page.\n\nMediaEval is a joint event with MMM 2024 and is an in-cooperation initiative with SIGMM the ACM Special Interest Group on Multimedia. There are discounts on MediaEval Workshop registration if you are attending MMM 2024 or if you are a SIGMM member. Note that SIGMM membership is 20 Euros, so it’s very much worthwhile to join SIGMM in order to receive the discount. Please let us know if you have any questions, especially about student discounts or need-based discounts. For our online participants, we are happy to announce that registration is free.\n\nFor in-person participants: The physical workshop will be held at the Amsterdam Science Park. On Wednesday 31 January at 17:00 there will be a cultural event and dinner. If possible, book travel to be at the Wednesday dinner. (But note there will be a MediaEval-specific dinner on Thursday.) More detailed information about preparing for the workshop and about workshop program and logistics will be sent to registered participants by email.\n\nAs you previously read in an email, accommodation information please see the MMM 2024 information page Here are some additional tips: There are no hotels at the Science Park, so you want to get a hotel with an easy bus connection (or consider renting a bike). We suggest hotels near Amsterdam Amstel Station. Hotel V Fizeaustraat is one we like not listed on the MMM 2024 page. Note there is a direct train from Amsterdam Schiphol Airport to Amsterdam Amstel Station, which takes about 20 minutes.\n"
      } ,
   
      {
        "title"    : "MediaEval 2023 Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2023/07/10/workshop-registration.html",
        "date"     : "July 10, 2023",
        "excerpt"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and fo...",
        "content"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focus on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nSignup for MediaEval 2023 is now open via the MediaEval 2023 registration form\n\nData release will start soon and continue over the next months. Runs will be due at the end of November 2023 and the annual MediaEval Workshop will be held 1-2 February 2024 co-located with the 30th International Conference on Multimedia Modeling MMM 2024. Remote participation will be possible for those who cannot travel to take part in the workshop in person.\n\nMediaEval 2023 is offering the following tasks:\n\n\n  Medico: Medical Multimedia Task: Transparent Tracking of Spermatozoa\n  Musti: Multimodal Understanding of Smells in Texts and Images\n  NewsImages: Connecting Images and Text\n  Predicting Video Memorability\n  SportsVideo: Fine Grained Action Classification and Position Detection in Table Tennis and Swimming Videos\n\n\nMore detailed task descriptions are available on the MediaEval 2023 Website.\n"
      } ,
   
      {
        "title"    : "MediaEval 2023 Call for Task Proposals",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2023/01/20/call.html",
        "date"     : "January 20, 2023",
        "excerpt"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate n...",
        "content"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2023 benchmarking season.\n\n\n  Early bird deadline: 3 March 2023\n  Final deadline: 10 May 2023 (updated)\n\n\nThe proposal should describe the motivation of the task, including a description of the use scenario in which the results of the tasks would be used (e.g., application that serves users). It should provide a definition of the specific problem that task participants are required to solve. Also, it should include information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated (the metric and description of how the metric is related to the use scenario). We ask you to think carefully about specific research questions that are related to the challenge, and mention these in the proposal. These research questions will guide participants in pursuing the “Quest for Insight”, i.e., going beyond thinking only about evaluation scores. Finally, the proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art.\n\nIndication of Intent\n\nIf you plan to submit a task proposal, we strongly suggest that you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what participants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.\n\nFull Task Proposal\n\nA task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.\n\nPart I: Task Description\n\nThis is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:\n\n\n  Task title: Give your task an informative title.\n  Task description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.\n  Motivation and background: Describe the motivating use scenario, i.e., how would the results of the task be used in an application that serves users. Also, state how the task extends the state of the art.\n  Target group: Describe the type of researchers who would be interested in participating in the task.\n  Data: Describe the data, including how the data will be collected and licensed.\n  Evaluation methodology: Describe the evaluation methodology, including how the ground truth will be created and the evaluation metrics.\n  “Quest for Insight”: List several research questions related to the challenge, which the participants can strive to answer in order to go beyond just looking at evaluation metrics.\n  References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.\n  List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.) For example task descriptions, please see the task pages of the MediaEval 2021 Tasks.\n\n\nPart II: Big Picture of the Task\n\nPlease address each of the following points with 2-3 sentences each:\n\nInnovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task.\nFocus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible research that makes multimedia a positive force for society. Please comment on the human or social aspect of your task.\nRisk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will you face in organizing the task and how do you expect to overcome them)?\n\nPart III: Task Organization Team\n\nWrite a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out failure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting early-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.\n\nSubmission\n\nPlease submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl with Steven Hicks steven (at) simula (dot) no and Mihai Gabriel (Gabi) Constantin mihai.constantin84 (at) upb (dot) ro on cc.\n\nMediaEval 2023 Schedule\n\nMay-June: Validation data release\nJune-August: Test data related\nEnd October: Runs due\nEnd November: Working notes papers due\nJanuary 2024: MediaEval 2023 Workshop, Collocated with MMM 2024 in Amsterdam, Netherlands and also online.\n"
      } ,
   
      {
        "title"    : "MediaEval Workshop Information",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2023/01/06/workshop-information.html",
        "date"     : "January 6, 2023",
        "excerpt"  : "The MediaEval 2022 workshop will take place Thursday-Friday 12-13 January 2023 as a hybrid workshop in person in Bergen, Norway and also online.\n\nThe in-person venue of the workshop is Media City Bergen (Lars Hilles gate 30, 5008 Bergen)...",
        "content"  : "The MediaEval 2022 workshop will take place Thursday-Friday 12-13 January 2023 as a hybrid workshop in person in Bergen, Norway and also online.\n\nThe in-person venue of the workshop is Media City Bergen (Lars Hilles gate 30, 5008 Bergen) https://goo.gl/maps/yrf9QD46hbRGJC2D9 Registration opens at 8:30 on Thursday morning and the first session starts at 9:00 in the Redaksjonsrom. Registered workshop participants have also received an email with the links (Zoom and Discord) to participate in the workshop online.\n\nHere is the high-level schedule of the workshop:\n\n\n\nFor the order of the individual talks, please see the Detailed MediaEval Workshop Schedule.\n\nThe preliminary workshop proceedings is available at: https://2022.multimediaeval.com/\n"
      } ,
   
      {
        "title"    : "MediaEval 2022 Workshop Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2022/11/16/workshop-registration.html",
        "date"     : "November 16, 2022",
        "excerpt"  : "MediaEval 2022 workshop Bergen, Norway, 12-13 January 2023, is co-located with the 29th International Conference on Multimedia Modeling (MMM). Note that the registration is separate from the registration to participate in the tasks (which you p...",
        "content"  : "MediaEval 2022 workshop Bergen, Norway, 12-13 January 2023, is co-located with the 29th International Conference on Multimedia Modeling (MMM). Note that the registration is separate from the registration to participate in the tasks (which you previously did).\n\nRegister for the workshop here: MediaEval Workshop Registration Website.\n\nPrices on the registration website are shown in Norwegian Kroner, NOK. Please read this announcement carefully, because it provides information about the program \nand also about the different categories of registration that support people with limited budget (or no budget!) to make it possible for them to present at the workshop.\n\nThere will be a welcome reception in the evening of Wednesday 11 January, and on Friday 13 January, the workshop will run the full day (i.e., until 17:30). Please plan \nyour travel accordingly. We will have AV facilities available so it is possible to follow the workshop and make your presentation online. Please choose the \n“online” option when registering for the workshop.\n\nIf you are the speaker who is giving the presentation, please register as “Presenting Author”. If you are an author who is not giving the presentation or a \ngeneral attendee, please use the “Regular” registration. (Prices are the same. This helps us make the program.)\n\n“Need-based registration” is for authors and other workshop attendees who have restricted budgets and cannot afford the full price. Typically, students, retirees, \nor participants from countries whose currency  is weak with respect to the Norwegian Kroner (NOK). Note that we count on you paying the full registration fee \nif you can afford it, and only choose  “need-based registration” if you cannot afford it. Paying the full registration fee will make it possible for us to make \nsure that we can cover the budget of the workshop.\n\nIf you are a student and have problems attending the workshop because of lack of funding, please get in touch with your task organizers. There is some funding \navailable to make it possible for students who do not have large travel budgets to attend the workshop.\n\nIf you are an author of a paper that will be presented at the MediaEval Workshop and need a visa, please register immediately for the workshop, and then contact \nmmm2023registration (at) googlegroups (com), stating the you registered for MediaEval and the title of your paper and providing your first name, last name, \nand date of birth as in your travel document (passport, for example), your postal address, paper ID, and the paper title.\n\nPlease note that you will receive a registration confirmation as soon as you register, but that it may be up to a week before you receive the official receipt \n(which is generated by a payment system).\n"
      } ,
   
      {
        "title"    : "MediaEval 2022 Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2022/06/16/registration-2022.html",
        "date"     : "June 16, 2022",
        "excerpt"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and fo...",
        "content"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focus on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nSignup for MediaEval 2022 is now open via the MediaEval 2022 registration form\n\nOnce you are signed up, fill out and return the MediaEval 2022 usage agreement to the email address given at the bottom of the first page.\n\nData release will start soon and continue over the next months. Runs will be due in November 2022 and the annual MediaEval Workshop will be held 12-13 January 2023 co-located with the 29th International Conference on Multimedia Modeling MMM 2023. Remote participation will be possible for those who cannot travel to take part in the workshop in person.\n\nMediaEval 2022 is offering the following tasks:\n\n\n  DisasterMM: Multimedia Analysis of Disaster-Related Social Media Data\n  Emotional Mario: A Game Analytics Challenge\n  FakeNews: Fake News Detection\n  Medico: Medical Multimedia Task: Transparent Tracking of Spermatozoa\n  Musti: Multimodal Understanding of Smells in Texts and Images\n  NewsImages: Relating news articles and images\n  NjordVid: Fishing Trawler Video Analytics Task\n  Memorability: Predicting Video Memorability\n  Sports Video: Fine Grained Action Detection and Classification of Table Tennis Strokes from videos\n  SwimTrack: Swimmers and Stroke Rate Detection in Elite Race Videos\n  Urban Air: Urban Life and Air Pollution\n\n\nMore detailed task descriptions are available on the MediaEval 2022 Website.\n"
      } ,
   
      {
        "title"    : "MediaEval 2022 Call for Task Proposals",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2022/01/26/call.html",
        "date"     : "January 26, 2022",
        "excerpt"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate n...",
        "content"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2022 benchmarking season.\n\nProposal deadline is 14 April 2022 (updatd deadline).\n\nThe proposal should describe the motivation of the task, including a description of the use scenario in which the results of the tasks would be used (e.g., application that serves users). It should provide a definition of the specific problem that task participants are required to solve. Also, it should include information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated (the metric and description of how the metric is related to the use scenario). We ask you to think carefully about specific research questions that are related to the challenge, and mention these in the proposal. These research questions will guide participants in pursuing the “Quest for Insight”, i.e., going beyond thinking only about evaluation scores. Finally, the proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art.\n\nIndication of Intent\n\nIf you plan to submit a task proposal, we strongly suggest that you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what participants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.\n\nFull Task Proposal\n\nA task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.\n\nPart I: Task Description\n\nThis is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:\n\n\n  Task title: Give your task an informative title.\n  Task description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.\n  Motivation and background: Describe the motivating use scenario, i.e., how would the results of the task be used in an application that serves users. Also, state how the task extends the state of the art.\n  Target group: Describe the type of researchers who would be interested in participating in the task.\n  Data: Describe the data, including how the data will be collected and licensed.\n  Evaluation methodology: Describe the evaluation methodology, including how the ground truth will be created and the evaluation metrics.\n  “Quest for Insight”: List several research questions related to the challenge, which the participants can strive to answer in order to go beyond just looking at evaluation metrics.\n  References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.\n  List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.) For example task descriptions, please see the task pages of the MediaEval 2021 Tasks.\n\n\nPart II: Big Picture of the Task\n\nPlease address each of the following points with 2-3 sentences each:\n\nInnovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task.\nFocus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible research that makes multimedia a positive force for society. Please comment on the human or social aspect of your task.\nRisk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will you face in organizing the task and how do you expect to overcome them)?\n\nPart III: Task Organization Team\n\nWrite a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out failure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting early-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.\n\nThe MediaEval 2022 Workshop will be held in early December 2022. We are planning on a physical workshop in Bergen, Norway with the opportunity for remote participation.\n\nPlease submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl and Gareth Jones gareth (dot) jones (at) computing (dot) dcu (dot) ie\n"
      } ,
   
      {
        "title"    : "MediaEval 2021 Workshop",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2021/12/03/workshop.html",
        "date"     : "December 3, 2021",
        "excerpt"  : "Workshop registration is now open for the 2021 edition of the MediaEval Multiedia Evaluation workshop. \nRegistration link and more information is available on the MediaEval 2021 webpage&lt;/...",
        "content"  : "Workshop registration is now open for the 2021 edition of the MediaEval Multiedia Evaluation workshop. \nRegistration link and more information is available on the MediaEval 2021 webpage Multimedia Evaluation Workshop is underway. \nThe workshop runs from 14:00-18:30 CET on Monday 13 December through Wednesday 15 December 2020 and is fully online.\n\nThe goal of the workshop is to gain insight into MediaEval tasks and how they can be solved. \nTeams will be talking about how they addressed the tasks, but also about why they chose the solution that they did and about what they learned. \nWe are looking forward to a dynamic and productive workshop.\n"
      } ,
   
      {
        "title"    : "MediaEval 2021 Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2021/06/16/registration-2021.html",
        "date"     : "June 16, 2021",
        "excerpt"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and fo...",
        "content"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focus on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nRegistration for participation in MediaEval 2021 is now open. Please visit the MediaEval 2021 webpage for more information and the link to the registration page.\n"
      } ,
   
      {
        "title"    : "Call for Task Proposals MediaEval 2021",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2021/03/02/call-2021.html",
        "date"     : "March 2, 2021",
        "excerpt"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks ar...",
        "content"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society\n\nMediaEval is now calling for proposals for tasks to run in the 2021 benchmarking season.\n\nFull proposal deadline: Wednesday 31 March 2021\n\nThe proposal should describe the motivation of the task and define the specific problem that task participants are required to solve. It should provide information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated. The proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art in an area related to multimedia indexing, search or other technologies that support users in accessing multimedia content and collections.\n\nIndication of Intent\nIf you plan to submit a task proposal, we strongly suggest that as soon as possible you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what participants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.\n\nFull Task Proposal\nA task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.\n\nPart I: Task Description\nThis is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:\n\n  Task Title: Give your task an informative title.\n  Task Description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.\n  Motivation and background: Describe the motivating use scenario, i.e., which application(s) motivate the task. State how the task extends the state of the art.\n  Target Group: Describe the type of researchers who would be interested in participating in the task.\n  Data: Describe the data, including how the data will be collected and licensed.\n  Evaluation Methodology: Describe the evaluation methodology, including how the ground truth will be created.\n  References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.\n  List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.)\nFor example task descriptions, please see the task pages of the MediaEval 2020 Tasks\n\n\nPart II: Big Picture of the Task\nPlease address each of the following points with 2-3 sentences each:\n\n  Innovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task.\n  Focus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible research that makes multimedia a positive force for society. Please comment on the human or social aspect of your task.\n  Risk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will you face in organizing the task and how do you expect to overcome them)?\n\n\nPart III: Task Organization Team\nWrite a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out failure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting early-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.\n\nThe MediaEval 2021 Workshop will be held in early December 2021. We are planning on a physical workshop in Bergen, Norway with the opportunity for remote participation.\n\nPlease submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl and Gareth Jones gareth (dot) jones (at) computing (dot) dcu (dot) ie\n\n"
      } ,
   
      {
        "title"    : "Announcing MediaEval 2021",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2020/12/15/annoucing-2021.html",
        "date"     : "December 15, 2020",
        "excerpt"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia analysis, access and exploration. MediaEval tasks are...",
        "content"  : "The Multimedia Evaluation Benchmark, MediaEval, offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia analysis, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society\n\nMediaEval is calling for proposals for tasks to run in the 2021 benchmarking season. The proposal should describe the motivation of the task and define the specific problem that task participants are required to solve. It should provide information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated. The proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art in an area related to multimedia indexing, search or other technologies that support users in accessing multimedia content and collections.\n\n\n"
      } ,
   
      {
        "title"    : "MediaEval 2020 Workshop",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2020/12/13/workshop.html",
        "date"     : "December 13, 2020",
        "excerpt"  : "The MediaEval 2020 Multimedia Evaluation Workshop is underway. The main workshop runs from 14:00-19:00 CET on Monday 14 December and Tuesday 15 December 2020. For more information on the workshop program and also the registration link that you ...",
        "content"  : "The MediaEval 2020 Multimedia Evaluation Workshop is underway. The main workshop runs from 14:00-19:00 CET on Monday 14 December and Tuesday 15 December 2020. For more information on the workshop program and also the registration link that you can use to sign up to attend, please see the MediaEval 2020 webpage\n"
      } ,
   
      {
        "title"    : "MediaEval 2020 Registration",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2020/07/24/registration2020.html",
        "date"     : "July 24, 2020",
        "excerpt"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and fo...",
        "content"  : "The Benchmarking Initiative for Multimedia Evaluation (MediaEval) offers challenges related to multimedia analysis, retrieval and exploration. MediaEval tasks involve multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focus on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nRegistration for participation in MediaEval 2020 is now open. Please visit the MediaEval 2020 webpage for more information and the link to the registration page.\n"
      } ,
   
      {
        "title"    : "Announcing MediaEval 2020",
        "category" : "",
        "tags"     : " ",
        "url"      : "/2020/06/01/annoucing-2020.html",
        "date"     : "June 1, 2020",
        "excerpt"  : "The Multimedia Evaluation Benchmark (MediaEval) offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks ar...",
        "content"  : "The Multimedia Evaluation Benchmark (MediaEval) offers challenges in the form of shared tasks. The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access and exploration. MediaEval tasks are innovative, involving multiple modalities, (e.g., audio, visual, textual, and/or contextual) and focusing on the human and social aspects of multimedia. Our larger aim is to promote reproducible research that makes multimedia a positive force for society.\n\nIn 2020, MediaEval will take place entirely online. Signup will open very soon. Watch this website for more information.\n\nThis year we will again be offering an interesting line up of tasks related to images, video, music, user interaction data, sensor data, lifelogging data. The tasks that MediaEval will offer in 2020 include:\n\n\n  Emotion and theme recognition in music\n  Emotional Mario: Believable AI agents in Video Games\n  Fake news detection\n  Insight for Wellbeing: Multimodal personal health lifelog data analysis\n  Medico Medical Multimedia\n  Multimedia Recommender Systems\n  No-audio Multimodal Speech Detection\n  Pixel Privacy\n  Predicting Media Memorability\n\n\nTasks will release data starting at the beginning of July and submissions will be due in November. The online workshop will be held at the beginning of December, exact dates to be announced.  For more information watch this website or contact Martha Larson m.larson at cs.ru.nl\n"
      } 
   
   
   
]