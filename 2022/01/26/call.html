<!DOCTYPE html>

<html lang="en">
  <head>
  <meta charset="UTF-8">
  <link rel="shortcut icon" href="/assets/img/mediaeval-favicon.png" type="image/png">
  <!--Import Google Icon Font-->
  <link href="https://fonts.googleapis.com/icon?family=Material+Icons" rel="stylesheet">
  <!--Import materialize.css-->
  <link type="text/css" rel="stylesheet" href="/assets/css/materialize.min.css"  media="screen,projection"/>
  <link type="text/css" rel="stylesheet" href="/assets/css/main.css"  media="screen,projection"/>
  <!-- Add icon library -->
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
  <!--Let browser know website is optimized for mobile-->
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <meta name="twitter:card" content="summary" /> <!--<meta name="twitter:card" content="summary_large_image" />-->
  <meta name="twitter:image" content="https://multimediaeval.github.io/assets/img/twitter-card-summary.png"/>
  <meta name="twitter:image:alt" content="Picture of group of people participants of the 2019 MediaEval workshop"/>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  

  <!-- seo tags -->
  <!-- Begin Jekyll SEO tag v2.6.1 -->
<title>MediaEval 2022 Call for Task Proposals | MediaEval Benchmark</title>
<meta name="generator" content="Jekyll v3.9.0" />
<meta property="og:title" content="MediaEval 2022 Call for Task Proposals" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2022 benchmarking season." />
<meta property="og:description" content="The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2022 benchmarking season." />
<link rel="canonical" href="https://multimediaeval.github.io/2022/01/26/call.html" />
<meta property="og:url" content="https://multimediaeval.github.io/2022/01/26/call.html" />
<meta property="og:site_name" content="MediaEval Benchmark" />
<meta property="og:image" content="https://multimediaeval.github.io/assets/img/twitter-card.png" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2022-01-26T00:00:00+00:00" />
<script type="application/ld+json">
{"image":"https://multimediaeval.github.io/assets/img/twitter-card.png","@type":"BlogPosting","url":"https://multimediaeval.github.io/2022/01/26/call.html","headline":"MediaEval 2022 Call for Task Proposals","dateModified":"2022-01-26T00:00:00+00:00","datePublished":"2022-01-26T00:00:00+00:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://multimediaeval.github.io/2022/01/26/call.html"},"description":"The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2022 benchmarking season.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <!-- Manual seo tags -->

</head>

  <body>

    <div>
    


<div class="navbar-fixed">
  <nav>
    <div class="nav-wrapper green darken-4">
      <a href="/" class="brand-logo" style="padding-left: 20px">
        <h3 class="northumbria" style="margin-top: 20px;color:white;">Mediaeval</h3>
      </a>
      <!-- Small screen definition -->
      <a href="#" data-target="mobile-nav" class="sidenav-trigger">
        <i class="material-icons" style="color:white;">menu</i>
      </a>
      <!-- Big screen Structure -->
      <ul class="materialize right hide-on-med-and-down">
        <li><a href="/"><i class="material-icons" style="color:white;">home</i></a></li>
        
          <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
        
        
          
            
              <li><a class="dropdown-trigger" data-target="editions" style="color:white;">
                MediaEval History<i class="material-icons right">arrow_drop_down</i>
              </a></li>
            
          
        
          
            
              <li><a href="/about/" style="color:white;">About MediaEval</a></li>
            
          
        
          
            
              <li><a href="/bib/" style="color:white;">Bibliography</a></li>
            
          
        
          
        
          
        
          
        
          
        
          
        
      </ul>
    </div>
  </nav>
</div>

<!-- Big screen dropdown Structure -->
<ul class="dropdown-content materialize" id="editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

<!-- Mobile Structure -->
<ul class="materialize sidenav green darken-4" id="mobile-nav">
  <li><a href="/" style="color:white;">Home</a></li>
  
  <li><a href="/editions/2022/" style="color:white;">MediaEval 2022</a></li>
  
  
    
      
  <li><a class="dropdown-trigger" data-target="mobile-editions" style="color:white;">
    MediaEval History<i class="material-icons right" style="color:white;">arrow_drop_down</i>
  </a></li>
      
    
  
    
      
  <li><a href="/about/" style="color:white;">About MediaEval</a></li>
      
    
  
    
      
  <li><a href="/bib/" style="color:white;">Bibliography</a></li>
      
    
  
    
  
    
  
    
  
    
  
    
  
</ul>

<!-- Mobile dropdown Structure -->
<ul class="dropdown-content materialize" id="mobile-editions">
  
  <li><a href="/editions/2021/">MediaEval 2021</a></li>
  
  <li><a href="/editions/2020/">MediaEval 2020</a></li>
  
  <li><a href="http://www.multimediaeval.org/" target="_blank">pre-2020</a></li>
</ul>

</div>

    

    <div class="container">
      <div class="row">
        <article >
  <header id="main" style="">
    
      <h1 id="MediaEval+2022+Call+for+Task+Proposals" class="title">MediaEval 2022 Call for Task Proposals</h1>
      <div class="post-info">
    <p class="meta">
      January 26, 2022
    </p>
</div>

    
  </header>
  <section class="post-content">
  
      <p>The Multimedia Evaluation Benchmark, MediaEval, offers challenges in artificial intelligence related to data that includes multiple modalities (e.g., audio, visual, textual, and/or contextual). The goal of MediaEval is to develop and evaluate new algorithms and technologies for multimedia retrieval, access, exploration and analysis. MediaEval pursues a “Quest for Insight”: we push beyond improving evaluation scores to achieving deeper understanding about the challenges, including data and the strengths and weaknesses of particular types of approaches. Our larger aim is to promote reproducible research that makes multimedia a positive force for society. MediaEval is now calling for proposals for tasks to run in the 2022 benchmarking season.</p>

<p>Proposal dealind is 14 April 2022 (update deadline).</p>

<p>The proposal should describe the motivation of the task, including a description of the use scenario in which the results of the tasks would be used (e.g., application that serves users). It should provide a definition of the specific problem that task participants are required to solve. Also, it should include information on the data (including source and licensing), and on how the solutions developed by task participants will be evaluated (the metric and description of how the metric is related to the use scenario). We ask you to think carefully about specific research questions that are related to the challenge, and mention these in the proposal. These research questions will guide participants in pursuing the “Quest for Insight”, i.e., going beyond thinking only about evaluation scores. Finally, the proposal must also include a statement of how the task is related to MediaEval (i.e., the human or social component), and how it extends the state of the art.</p>

<h5 id="indication-of-intent">Indication of Intent</h5>

<p>If you plan to submit a task proposal, we strongly suggest that you submit, by email, an “Indication of Intent” in the form of a short task summary (a blurb of 50-100 words) as soon as possible. The description should include a clear statement of what participants are expected to do, which data is used, and how participant submissions are evaluated. The summary should finish with a statement of the motivation for the task.</p>

<h5 id="full-task-proposal">Full Task Proposal</h5>

<p>A task proposal contains the following elements. Note that there is no specified length for the proposal, but in general proposals do not exceed three pages.</p>

<h6 id="part-i-task-description">Part I: Task Description</h6>

<p>This is a version of your task description that will be posted to the MediaEval website. Its goal is to inform and attract the interest of potential participants. It consists of the following parts:</p>

<ul>
  <li>Task title: Give your task an informative title.</li>
  <li>Task description: State the goal of the task and what is expected of task participants in a simple easy-to-understand manner. The task description should make clear what the task requires of participants.</li>
  <li>Motivation and background: Describe the motivating use scenario, i.e., how would the results of the task be used in an application that serves users. Also, state how the task extends the state of the art.</li>
  <li>Target troup: Describe the type of researchers who would be interested in participating in the task.</li>
  <li>Data: Describe the data, including how the data will be collected and licensed.</li>
  <li>Evaluation methodology: Describe the evaluation methodology, including how the ground truth will be created and the evaluation metrics.</li>
  <li>“Quest for Insight”: List several research questions related to the challenge, which the participants can strive to answer in order to go beyond just looking at evaluation metrics.</li>
  <li>References and recommended reading: list 3-4 references related to the task that teams should have read before attempting the task.</li>
  <li>List of task organizers. (Designate a lead task organizer whose contact details will appear on the website for the task.) For example task descriptions, please see the task pages of the MediaEval 2021 Tasks.</li>
</ul>

<h6 id="part-ii-big-picture-of-the-task">Part II: Big Picture of the Task</h6>

<p>Please address each of the following points with 2-3 sentences each:</p>

<p>Innovation: MediaEval strives to offer innovative tasks. New tasks open up new terrain for multimedia researchers, continuing tasks introduce novel aspects every year that drive forward the state of the art. Describe the novel contribution of your task.
Focus: MediaEval focuses on tasks that have a human or social aspect. This means that they serve groups of users, work with multimedia content produced by users, and/or address issues of affect and subjectivity. MediaEval strives to promote reproducible research that makes multimedia a positive force for society. Please comment on the human or social aspect of your task.
Risk management: What are the main risks that you foresee for the task, and how you plan to address them (i.e., what challenges will you face in organizing the task and how do you expect to overcome them)?</p>

<h6 id="part-iii-task-organization-team">Part III: Task Organization Team</h6>

<p>Write a very brief paragraph outlining the relevant interests and experience of your organizing team. Your team should be large enough to handle the organization and management of the task. This includes evaluating participant runs, and carrying out failure analysis on the results. Ideally teams should consist of members from multiple research sites and multiple projects. A mix of experienced and early-career researchers is preferred. MediaEval has a strong tradition of encouraging and supporting early-stage researchers in gaining experience in organization of benchmark tasks. Note that your task team can add members after the proposal has been accepted.</p>

<p>The MediaEval 2022 Workshop will be held in early December 2022. We are planning on a physical workshop in Bergen, Norway with the opportunity for remote participation.</p>

<p>Please submit your proposal (as a text file, .doc, .docx or link to an editable Google doc file) by emailing it to Martha Larson m (dot) larson (at) cs (dot) ru (dot) nl and Gareth Jones gareth (dot) jones (at) computing (dot) dcu (dot) ie</p>

    
  </section>

  <!-- Social media shares -->
  <!-- <div class="share-buttons">
    <ul class="share-buttons">
        <div class="meta">Share</div>
                
    </ul>
</div>
 -->

   <!-- Tag list -->
  <!-- 
  


<footer>
  <div class="tag-list"></div>
</footer>
 -->

</article>

<!-- Post navigation -->

  <div id="post-nav">
    
    

    <div id="next-post">
        <p>Previous post</p>
        <a alt="MediaEval 2021 Workshop" href="/2021/12/03/workshop.html">
            MediaEval 2021 Workshop
        </a>
    </div>
    
</div>



      </div>
    </div>

    
<footer class='page-footer green darken-4'>
  <div class='container'>

    <div class='row'>
      <div class="col l6 s12">
        <h5 class="white-text">What is MediaEval?</h5>
        <p>MediaEval is a benchmarking initiative dedicated to evaluating new algorithms for multimedia access and retrieval. 
          It emphasizes the ‘multi’ in multimedia and focuses on human and social aspects of multimedia tasks.</p>

        <p>For more information contact Martha Larson m.larson (at) cs.ru.nl</p>
      </div>
      <div class="col l4 offset-l2 s12">
        <h5 class="white-text">Links</h5>
        <a href='https://twitter.com/multimediaeval' target="_blank">
          <i class="fa fa-twitter fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://github.com/multimediaeval' target="_blank">
          <i class="fa fa-github fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.flickr.com/photos/69524595@N06/' target="_blank">
          <i class="fa fa-flickr fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
        <a href='https://www.youtube.com/channel/UCc-1NW1Uo2o_zI4F81iyTcw' target="_blank">
          <i class="fa fa-youtube fa-3x" aria-hidden="true" style="color:white;"></i>
        </a>
      </div>
    </div>

  </div>
    <div class="footer-copyright">
      <div class="container grey-text text-lighten-4">
      &copy; 2020 MediaEval Multimedia Benchmark
    </div>
  </div>
</footer>


    <!--JavaScript at end of body for optimized loading-->
    <script type="text/javascript" src="/assets/js/materialize.min.js"></script>
    <script type="text/javascript" src="/assets/js/main.js"></script>
  </body>

</html>
